{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_CxaQc9PdLCq"
   },
   "outputs": [],
   "source": [
    "# library import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fl4myqXOhwi5",
    "outputId": "a837e73a-bb95-4cec-aa32-5accd6e44ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# gpu 사용하기\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "T4KLlt6DdYZg"
   },
   "outputs": [],
   "source": [
    "# 데이터 가져오기\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "train_data_drop = train_data.dropna()\n",
    "\n",
    "# 데이터 쪼개기 => 결측치 제거한 값으로\n",
    "idx1to26_drop = train_data_drop.iloc[:, 1:27]\n",
    "idx28to40_drop = train_data_drop.iloc[:, 28:41]\n",
    "idx41to56_drop = train_data_drop.iloc[:, 41:57]\n",
    "idx57to68_drop = train_data_drop.iloc[:, 57:69]\n",
    "target_drop = train_data_drop.iloc[:, 69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CbJiq-H_g61q"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "main_train_input, main_test_input, main_train_target, main_test_target = train_test_split(idx1to26_drop, target_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v8YeNZakhMVc"
   },
   "outputs": [],
   "source": [
    "# CustomDataset\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, input, target):\n",
    "    self.input = input\n",
    "    self.target = target\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.target)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    sample = torch.tensor(self.input.iloc[idx, :]).float()\n",
    "    label = torch.tensor(self.target.iloc[idx]).float()\n",
    "    return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "thJ0Le_ChahQ"
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(main_train_input, main_train_target)\n",
    "test_dataset = CustomDataset(main_test_input, main_test_target)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfJ5IqEBhfjp",
    "outputId": "fc45d842-794a-4133-9d52-b3f296ac32b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (fc1): Linear(in_features=26, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc4): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (fc5): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NN(nn.Module):\n",
    "  def __init__(self):\n",
    "    # nn 모듈을 사용하는 경우에는 모두 init안에 정의를 해 주어야 한다.\n",
    "    \n",
    "    # 신경망의 구조\n",
    "    # 여러분의 아이디어가 필요한 부분입니다!\n",
    "    # 어쩌면 선형 모델을 이용한건 0.72가 최선일 수 있습니다.\n",
    "    # 조금 더 시도해 보다가 안된다면, 그냥 Ensemble Learning의 1개의 요소로만 쓰고, 다른 모델에 더 투자해 보죠!\n",
    "    \n",
    "    # 고려할 부분\n",
    "    # 신경망의 개수\n",
    "    # 줄어드는 차원의 방식\n",
    "    # dropout\n",
    "    super(NN, self).__init__()\n",
    "    self.fc1 = nn.Linear(in_features=26, out_features=20)\n",
    "    self.fc2 = nn.Linear(in_features=20, out_features=16)\n",
    "    self.fc3 = nn.Linear(in_features=16, out_features=8)\n",
    "    self.fc4 = nn.Linear(in_features=8, out_features=4)\n",
    "    self.fc5 = nn.Linear(in_features=4, out_features=1)\n",
    "    self.drop = nn.Dropout(0.3)\n",
    "\n",
    "  def forward(self, input_data):\n",
    "    out = F.relu(self.fc1(input_data))\n",
    "    out = self.drop(out)\n",
    "    out = F.relu(self.fc2(out))\n",
    "    out = F.relu(self.fc3(out))\n",
    "    out = F.relu(self.fc4(out))\n",
    "    out = torch.sigmoid(self.fc5(out))\n",
    "    return out\n",
    "\n",
    "# 모델 객체 생성\n",
    "model_main = NN().to(device)\n",
    "print(model_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4V9xI4j9h0Yw"
   },
   "outputs": [],
   "source": [
    "# loss = Binary Cross Entropy Loss\n",
    "# optimizer = adam\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_main.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gshT0LX8h1YA"
   },
   "outputs": [],
   "source": [
    "# epoch는 200으로 한다.\n",
    "epochs = 200\n",
    "aggregated_losses = []\n",
    "for i in range(epochs):\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        output = model_main(x).view(-1)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-cy6q41jOWQ",
    "outputId": "ed7cdd98-744a-4868-9149-2a309a9b5c5a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /Users/munseongsu/opt/anaconda3/envs/torch_book/lib/python3.9/site-packages (0.9.3)\n",
      "Requirement already satisfied: torch>=1.3.1 in /Users/munseongsu/opt/anaconda3/envs/torch_book/lib/python3.9/site-packages (from torchmetrics) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/munseongsu/opt/anaconda3/envs/torch_book/lib/python3.9/site-packages (from torchmetrics) (1.22.3)\n",
      "Requirement already satisfied: packaging in /Users/munseongsu/opt/anaconda3/envs/torch_book/lib/python3.9/site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: typing_extensions in /Users/munseongsu/opt/anaconda3/envs/torch_book/lib/python3.9/site-packages (from torch>=1.3.1->torchmetrics) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/munseongsu/opt/anaconda3/envs/torch_book/lib/python3.9/site-packages (from packaging->torchmetrics) (3.0.9)\n",
      "0.7193037867546082\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가 코드\n",
    "! pip install torchmetrics\n",
    "import torchmetrics\n",
    "\n",
    "metrics = torchmetrics.Accuracy()\n",
    "\n",
    "predict = torch.round(model_main(torch.Tensor(main_test_input.to_numpy()).to(device)))\n",
    "target = torch.tensor(main_test_target.to_numpy())\n",
    "\n",
    "acc = torchmetrics.functional.accuracy(predict, target.to(device))\n",
    "print(acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/fhzpwcq55y92813bgqv03qrh0000gn/T/ipykernel_18217/2775800848.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  test_data_rpm = test_data.fillna(test_data.mean())\n"
     ]
    }
   ],
   "source": [
    "# 제출용 csv 파일 만들기\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data_rpm = test_data.fillna(test_data.mean())\n",
    "idx1to26_rpm = test_data_rpm.iloc[:, 1:27]\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "predict = torch.round(model_main(torch.Tensor(idx1to26_rpm.to_numpy()).to(device)))\n",
    "submission[\"nerdiness\"] = predict.detach().numpy().astype(np.int32)\n",
    "\n",
    "submission.to_csv(\"submission1.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model_Dev2_pytorch.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
