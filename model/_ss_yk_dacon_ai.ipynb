{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "\bss_yk_dacon_ai.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 셋 생성을 위한 코드"
      ],
      "metadata": {
        "id": "VwZdhLEsHrQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# library import \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "9_OzXf_uHwVv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 표 전체 보기\n",
        "print(\"pandas version: \", pd.__version__)\n",
        "pd.set_option('display.max_row', 500)\n",
        "pd.set_option('display.max_columns', 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsyaFHkZP0g6",
        "outputId": "f398afb3-520b-4982-85e4-b40322d09a5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas version:  1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data read\n",
        "# data read는 드라이브 마운트가 되어있기 때문에 각자의 경로로 수정해 주셔야 합니다.\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "kGAGXuXnHyaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# missing value processing\n",
        "# median\n",
        "train.fillna(train.median(), inplace=True)  #결측값 변경\n",
        "test.fillna(train.median(), inplace=True)\n",
        "\n",
        "# contry 열 삭제\n",
        "train.drop(['country'], axis=1, inplace=True)\n",
        "test.drop(['country'], axis=1, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FriYP5UzHygE",
        "outputId": "8ba6f812-6fa4-439b-ba6e-56d601d4ae7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "O5P9g89gOw3f",
        "outputId": "21d42333-0169-4a6a-8182-c3b6e84026a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   index   Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10  Q11  Q12  Q13  \\\n",
              "0      0  1.0  5.0  5.0  5.0  1.0  4.0  5.0  5.0  1.0  3.0  5.0  5.0  5.0   \n",
              "1      1  4.0  4.0  4.0  4.0  4.0  5.0  4.0  4.0  3.0  3.0  1.0  4.0  5.0   \n",
              "2      2  4.0  5.0  5.0  4.0  3.0  5.0  5.0  5.0  4.0  4.0  2.0  5.0  5.0   \n",
              "3      3  4.0  4.0  4.0  2.0  4.0  3.0  3.0  5.0  3.0  4.0  5.0  2.0  2.0   \n",
              "4      4  4.0  4.0  4.0  4.0  3.0  3.0  4.0  2.0  3.0  4.0  4.0  4.0  3.0   \n",
              "5      5  5.0  4.0  5.0  5.0  5.0  5.0  5.0  4.0  4.0  3.0  4.0  5.0  2.0   \n",
              "6      6  4.0  3.0  4.0  3.0  5.0  4.0  5.0  4.0  5.0  5.0  3.0  5.0  5.0   \n",
              "7      7  4.0  5.0  4.0  4.0  4.0  4.0  2.0  5.0  3.0  4.0  2.0  2.0  3.0   \n",
              "8      8  4.0  4.0  3.0  4.0  4.0  5.0  4.0  3.0  3.0  4.0  4.0  4.0  3.0   \n",
              "9      9  3.0  3.0  4.0  3.0  4.0  2.0  4.0  2.0  4.0  4.0  5.0  4.0  1.0   \n",
              "\n",
              "   Q14  Q15  Q16  Q17  Q18  Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  \\\n",
              "0  5.0  5.0  5.0  5.0  1.0  5.0  5.0  1.0  5.0  1.0  5.0  1.0  1.0   \n",
              "1  3.0  1.0  2.0  4.0  5.0  1.0  3.0  1.0  1.0  5.0  3.0  2.0  5.0   \n",
              "2  5.0  1.0  3.0  5.0  3.0  5.0  2.0  2.0  1.0  2.0  4.0  2.0  5.0   \n",
              "3  4.0  4.0  2.0  4.0  5.0  4.0  3.0  3.0  4.0  3.0  4.0  4.0  2.0   \n",
              "4  5.0  5.0  2.0  4.0  1.0  4.0  2.0  4.0  2.0  3.0  4.0  4.0  4.0   \n",
              "5  3.0  4.0  1.0  1.0  2.0  4.0  2.0  2.0  2.0  3.0  5.0  3.0  5.0   \n",
              "6  3.0  3.0  3.0  5.0  5.0  3.0  4.0  4.0  3.0  5.0  5.0  3.0  5.0   \n",
              "7  3.0  5.0  2.0  4.0  5.0  2.0  3.0  5.0  3.0  5.0  5.0  1.0  4.0   \n",
              "8  3.0  3.0  1.0  2.0  4.0  1.0  3.0  1.0  2.0  5.0  3.0  1.0  4.0   \n",
              "9  4.0  2.0  5.0  4.0  4.0  5.0  3.0  1.0  1.0  2.0  4.0  4.0  2.0   \n",
              "\n",
              "   introelapse  testelapse  surveyelapse  TIPI1  TIPI2  TIPI3  TIPI4  TIPI5  \\\n",
              "0            3         553             6    4.0    3.0    5.0    1.0    3.0   \n",
              "1            5          85           120    4.0    2.0    3.0    5.0    3.0   \n",
              "2            9         108           100    1.0    2.0    3.0    1.0    5.0   \n",
              "3            2         121           139    3.0    3.0    3.0    4.0    5.0   \n",
              "4            3         640           216    3.0    3.0    4.0    4.0    4.0   \n",
              "5            3         100           176    5.0    3.0    3.0    3.0    5.0   \n",
              "6           17          88           164    3.0    2.0    5.0    3.0    4.0   \n",
              "7           20          53           112    3.0    2.0    5.0    5.0    3.0   \n",
              "8            9         164           213    3.0    1.0    4.0    3.0    4.0   \n",
              "9          109         134           177    2.0    2.0    5.0    3.0    3.0   \n",
              "\n",
              "   TIPI6  TIPI7  TIPI8  TIPI9  TIPI10  VCL1  VCL2  VCL3  VCL4  VCL5  VCL6  \\\n",
              "0    5.0    5.0    3.0    5.0     3.0     1     1     0     1     1     0   \n",
              "1    2.0    5.0    1.0    2.0     2.0     1     1     1     1     1     0   \n",
              "2    5.0    3.0    4.0    5.0     2.0     1     1     0     1     1     0   \n",
              "3    3.0    4.0    4.0    3.0     3.0     1     1     0     1     1     0   \n",
              "4    4.0    3.0    4.0    3.0     2.0     1     1     0     1     1     0   \n",
              "5    2.0    4.0    5.0    3.0     1.0     1     1     0     1     1     0   \n",
              "6    3.0    3.0    2.0    3.0     2.0     1     1     0     1     1     0   \n",
              "7    3.0    3.0    2.0    2.0     2.0     1     1     1     1     0     0   \n",
              "8    3.0    4.0    1.0    3.0     3.0     1     1     1     1     1     1   \n",
              "9    4.0    4.0    2.0    4.0     4.0     1     1     0     1     1     0   \n",
              "\n",
              "   VCL7  VCL8  VCL9  VCL10  VCL11  VCL12  VCL13  VCL14  VCL15  VCL16  \\\n",
              "0     0     0     0      1      0      0      0      1      1      1   \n",
              "1     1     0     0      1      0      0      1      1      1      1   \n",
              "2     1     1     0      1      0      0      1      1      1      1   \n",
              "3     0     0     0      1      0      0      1      1      1      1   \n",
              "4     0     1     0      1      0      0      0      1      0      1   \n",
              "5     0     1     0      1      0      0      1      1      1      1   \n",
              "6     0     0     0      1      0      0      1      1      1      1   \n",
              "7     0     1     0      1      1      0      1      1      1      1   \n",
              "8     0     0     0      1      0      0      1      1      1      1   \n",
              "9     0     0     0      1      0      0      1      1      1      1   \n",
              "\n",
              "   education  urban  gender  engnat  age  hand  religion  orientation  voted  \\\n",
              "0        2.0      1     3.0     1.0   20   2.0      12.0          4.0    2.0   \n",
              "1        4.0      2     2.0     1.0   49   1.0       2.0          1.0    1.0   \n",
              "2        2.0      1     1.0     2.0   43   1.0       2.0          2.0    2.0   \n",
              "3        1.0      3     1.0     1.0   17   2.0       1.0          1.0    2.0   \n",
              "4        1.0      2     2.0     2.0   18   2.0      12.0          1.0    2.0   \n",
              "5        3.0      2     1.0     1.0   26   1.0       1.0          1.0    1.0   \n",
              "6        4.0      3     2.0     2.0   40   1.0       1.0          1.0    2.0   \n",
              "7        3.0      1     2.0     2.0   34   1.0       2.0          5.0    1.0   \n",
              "8        2.0      2     2.0     1.0   20   1.0       7.0          1.0    1.0   \n",
              "9        2.0      2     1.0     2.0   17   1.0      10.0          1.0    2.0   \n",
              "\n",
              "   married  familysize  ASD  nerdiness  \n",
              "0      1.0         4.0  2.0          1  \n",
              "1      2.0         4.0  2.0          1  \n",
              "2      3.0         4.0  2.0          1  \n",
              "3      1.0         2.0  2.0          1  \n",
              "4      1.0         1.0  2.0          0  \n",
              "5      1.0         1.0  1.0          1  \n",
              "6      1.0         1.0  2.0          1  \n",
              "7      1.0         2.0  2.0          1  \n",
              "8      1.0         3.0  2.0          0  \n",
              "9      1.0         5.0  2.0          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b01192a-952a-441a-b572-43998e91d3d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>Q10</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16</th>\n",
              "      <th>Q17</th>\n",
              "      <th>Q18</th>\n",
              "      <th>Q19</th>\n",
              "      <th>Q20</th>\n",
              "      <th>Q21</th>\n",
              "      <th>Q22</th>\n",
              "      <th>Q23</th>\n",
              "      <th>Q24</th>\n",
              "      <th>Q25</th>\n",
              "      <th>Q26</th>\n",
              "      <th>introelapse</th>\n",
              "      <th>testelapse</th>\n",
              "      <th>surveyelapse</th>\n",
              "      <th>TIPI1</th>\n",
              "      <th>TIPI2</th>\n",
              "      <th>TIPI3</th>\n",
              "      <th>TIPI4</th>\n",
              "      <th>TIPI5</th>\n",
              "      <th>TIPI6</th>\n",
              "      <th>TIPI7</th>\n",
              "      <th>TIPI8</th>\n",
              "      <th>TIPI9</th>\n",
              "      <th>TIPI10</th>\n",
              "      <th>VCL1</th>\n",
              "      <th>VCL2</th>\n",
              "      <th>VCL3</th>\n",
              "      <th>VCL4</th>\n",
              "      <th>VCL5</th>\n",
              "      <th>VCL6</th>\n",
              "      <th>VCL7</th>\n",
              "      <th>VCL8</th>\n",
              "      <th>VCL9</th>\n",
              "      <th>VCL10</th>\n",
              "      <th>VCL11</th>\n",
              "      <th>VCL12</th>\n",
              "      <th>VCL13</th>\n",
              "      <th>VCL14</th>\n",
              "      <th>VCL15</th>\n",
              "      <th>VCL16</th>\n",
              "      <th>education</th>\n",
              "      <th>urban</th>\n",
              "      <th>gender</th>\n",
              "      <th>engnat</th>\n",
              "      <th>age</th>\n",
              "      <th>hand</th>\n",
              "      <th>religion</th>\n",
              "      <th>orientation</th>\n",
              "      <th>voted</th>\n",
              "      <th>married</th>\n",
              "      <th>familysize</th>\n",
              "      <th>ASD</th>\n",
              "      <th>nerdiness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>553</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>85</td>\n",
              "      <td>120</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>108</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>43</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "      <td>139</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>640</td>\n",
              "      <td>216</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>176</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17</td>\n",
              "      <td>88</td>\n",
              "      <td>164</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20</td>\n",
              "      <td>53</td>\n",
              "      <td>112</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9</td>\n",
              "      <td>164</td>\n",
              "      <td>213</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>109</td>\n",
              "      <td>134</td>\n",
              "      <td>177</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b01192a-952a-441a-b572-43998e91d3d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b01192a-952a-441a-b572-43998e91d3d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b01192a-952a-441a-b572-43998e91d3d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data_split\n",
        "train_input = train.iloc[:, :-1]\n",
        "train_target = train.iloc[:, -1]"
      ],
      "metadata": {
        "id": "W5wg4MaQHyl5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(train_input[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "ue13gRl-O9Ql",
        "outputId": "02167989-9f9d-4287-90f2-200bce31b449"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   index   Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10  Q11  Q12  Q13  \\\n",
              "0      0  1.0  5.0  5.0  5.0  1.0  4.0  5.0  5.0  1.0  3.0  5.0  5.0  5.0   \n",
              "1      1  4.0  4.0  4.0  4.0  4.0  5.0  4.0  4.0  3.0  3.0  1.0  4.0  5.0   \n",
              "2      2  4.0  5.0  5.0  4.0  3.0  5.0  5.0  5.0  4.0  4.0  2.0  5.0  5.0   \n",
              "3      3  4.0  4.0  4.0  2.0  4.0  3.0  3.0  5.0  3.0  4.0  5.0  2.0  2.0   \n",
              "4      4  4.0  4.0  4.0  4.0  3.0  3.0  4.0  2.0  3.0  4.0  4.0  4.0  3.0   \n",
              "5      5  5.0  4.0  5.0  5.0  5.0  5.0  5.0  4.0  4.0  3.0  4.0  5.0  2.0   \n",
              "6      6  4.0  3.0  4.0  3.0  5.0  4.0  5.0  4.0  5.0  5.0  3.0  5.0  5.0   \n",
              "7      7  4.0  5.0  4.0  4.0  4.0  4.0  2.0  5.0  3.0  4.0  2.0  2.0  3.0   \n",
              "8      8  4.0  4.0  3.0  4.0  4.0  5.0  4.0  3.0  3.0  4.0  4.0  4.0  3.0   \n",
              "9      9  3.0  3.0  4.0  3.0  4.0  2.0  4.0  2.0  4.0  4.0  5.0  4.0  1.0   \n",
              "\n",
              "   Q14  Q15  Q16  Q17  Q18  Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  \\\n",
              "0  5.0  5.0  5.0  5.0  1.0  5.0  5.0  1.0  5.0  1.0  5.0  1.0  1.0   \n",
              "1  3.0  1.0  2.0  4.0  5.0  1.0  3.0  1.0  1.0  5.0  3.0  2.0  5.0   \n",
              "2  5.0  1.0  3.0  5.0  3.0  5.0  2.0  2.0  1.0  2.0  4.0  2.0  5.0   \n",
              "3  4.0  4.0  2.0  4.0  5.0  4.0  3.0  3.0  4.0  3.0  4.0  4.0  2.0   \n",
              "4  5.0  5.0  2.0  4.0  1.0  4.0  2.0  4.0  2.0  3.0  4.0  4.0  4.0   \n",
              "5  3.0  4.0  1.0  1.0  2.0  4.0  2.0  2.0  2.0  3.0  5.0  3.0  5.0   \n",
              "6  3.0  3.0  3.0  5.0  5.0  3.0  4.0  4.0  3.0  5.0  5.0  3.0  5.0   \n",
              "7  3.0  5.0  2.0  4.0  5.0  2.0  3.0  5.0  3.0  5.0  5.0  1.0  4.0   \n",
              "8  3.0  3.0  1.0  2.0  4.0  1.0  3.0  1.0  2.0  5.0  3.0  1.0  4.0   \n",
              "9  4.0  2.0  5.0  4.0  4.0  5.0  3.0  1.0  1.0  2.0  4.0  4.0  2.0   \n",
              "\n",
              "   introelapse  testelapse  surveyelapse  TIPI1  TIPI2  TIPI3  TIPI4  TIPI5  \\\n",
              "0            3         553             6    4.0    3.0    5.0    1.0    3.0   \n",
              "1            5          85           120    4.0    2.0    3.0    5.0    3.0   \n",
              "2            9         108           100    1.0    2.0    3.0    1.0    5.0   \n",
              "3            2         121           139    3.0    3.0    3.0    4.0    5.0   \n",
              "4            3         640           216    3.0    3.0    4.0    4.0    4.0   \n",
              "5            3         100           176    5.0    3.0    3.0    3.0    5.0   \n",
              "6           17          88           164    3.0    2.0    5.0    3.0    4.0   \n",
              "7           20          53           112    3.0    2.0    5.0    5.0    3.0   \n",
              "8            9         164           213    3.0    1.0    4.0    3.0    4.0   \n",
              "9          109         134           177    2.0    2.0    5.0    3.0    3.0   \n",
              "\n",
              "   TIPI6  TIPI7  TIPI8  TIPI9  TIPI10  VCL1  VCL2  VCL3  VCL4  VCL5  VCL6  \\\n",
              "0    5.0    5.0    3.0    5.0     3.0     1     1     0     1     1     0   \n",
              "1    2.0    5.0    1.0    2.0     2.0     1     1     1     1     1     0   \n",
              "2    5.0    3.0    4.0    5.0     2.0     1     1     0     1     1     0   \n",
              "3    3.0    4.0    4.0    3.0     3.0     1     1     0     1     1     0   \n",
              "4    4.0    3.0    4.0    3.0     2.0     1     1     0     1     1     0   \n",
              "5    2.0    4.0    5.0    3.0     1.0     1     1     0     1     1     0   \n",
              "6    3.0    3.0    2.0    3.0     2.0     1     1     0     1     1     0   \n",
              "7    3.0    3.0    2.0    2.0     2.0     1     1     1     1     0     0   \n",
              "8    3.0    4.0    1.0    3.0     3.0     1     1     1     1     1     1   \n",
              "9    4.0    4.0    2.0    4.0     4.0     1     1     0     1     1     0   \n",
              "\n",
              "   VCL7  VCL8  VCL9  VCL10  VCL11  VCL12  VCL13  VCL14  VCL15  VCL16  \\\n",
              "0     0     0     0      1      0      0      0      1      1      1   \n",
              "1     1     0     0      1      0      0      1      1      1      1   \n",
              "2     1     1     0      1      0      0      1      1      1      1   \n",
              "3     0     0     0      1      0      0      1      1      1      1   \n",
              "4     0     1     0      1      0      0      0      1      0      1   \n",
              "5     0     1     0      1      0      0      1      1      1      1   \n",
              "6     0     0     0      1      0      0      1      1      1      1   \n",
              "7     0     1     0      1      1      0      1      1      1      1   \n",
              "8     0     0     0      1      0      0      1      1      1      1   \n",
              "9     0     0     0      1      0      0      1      1      1      1   \n",
              "\n",
              "   education  urban  gender  engnat  age  hand  religion  orientation  voted  \\\n",
              "0        2.0      1     3.0     1.0   20   2.0      12.0          4.0    2.0   \n",
              "1        4.0      2     2.0     1.0   49   1.0       2.0          1.0    1.0   \n",
              "2        2.0      1     1.0     2.0   43   1.0       2.0          2.0    2.0   \n",
              "3        1.0      3     1.0     1.0   17   2.0       1.0          1.0    2.0   \n",
              "4        1.0      2     2.0     2.0   18   2.0      12.0          1.0    2.0   \n",
              "5        3.0      2     1.0     1.0   26   1.0       1.0          1.0    1.0   \n",
              "6        4.0      3     2.0     2.0   40   1.0       1.0          1.0    2.0   \n",
              "7        3.0      1     2.0     2.0   34   1.0       2.0          5.0    1.0   \n",
              "8        2.0      2     2.0     1.0   20   1.0       7.0          1.0    1.0   \n",
              "9        2.0      2     1.0     2.0   17   1.0      10.0          1.0    2.0   \n",
              "\n",
              "   married  familysize  ASD  \n",
              "0      1.0         4.0  2.0  \n",
              "1      2.0         4.0  2.0  \n",
              "2      3.0         4.0  2.0  \n",
              "3      1.0         2.0  2.0  \n",
              "4      1.0         1.0  2.0  \n",
              "5      1.0         1.0  1.0  \n",
              "6      1.0         1.0  2.0  \n",
              "7      1.0         2.0  2.0  \n",
              "8      1.0         3.0  2.0  \n",
              "9      1.0         5.0  2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f1bc8ee-4fdd-4604-9d13-8edf0b3542cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>Q10</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16</th>\n",
              "      <th>Q17</th>\n",
              "      <th>Q18</th>\n",
              "      <th>Q19</th>\n",
              "      <th>Q20</th>\n",
              "      <th>Q21</th>\n",
              "      <th>Q22</th>\n",
              "      <th>Q23</th>\n",
              "      <th>Q24</th>\n",
              "      <th>Q25</th>\n",
              "      <th>Q26</th>\n",
              "      <th>introelapse</th>\n",
              "      <th>testelapse</th>\n",
              "      <th>surveyelapse</th>\n",
              "      <th>TIPI1</th>\n",
              "      <th>TIPI2</th>\n",
              "      <th>TIPI3</th>\n",
              "      <th>TIPI4</th>\n",
              "      <th>TIPI5</th>\n",
              "      <th>TIPI6</th>\n",
              "      <th>TIPI7</th>\n",
              "      <th>TIPI8</th>\n",
              "      <th>TIPI9</th>\n",
              "      <th>TIPI10</th>\n",
              "      <th>VCL1</th>\n",
              "      <th>VCL2</th>\n",
              "      <th>VCL3</th>\n",
              "      <th>VCL4</th>\n",
              "      <th>VCL5</th>\n",
              "      <th>VCL6</th>\n",
              "      <th>VCL7</th>\n",
              "      <th>VCL8</th>\n",
              "      <th>VCL9</th>\n",
              "      <th>VCL10</th>\n",
              "      <th>VCL11</th>\n",
              "      <th>VCL12</th>\n",
              "      <th>VCL13</th>\n",
              "      <th>VCL14</th>\n",
              "      <th>VCL15</th>\n",
              "      <th>VCL16</th>\n",
              "      <th>education</th>\n",
              "      <th>urban</th>\n",
              "      <th>gender</th>\n",
              "      <th>engnat</th>\n",
              "      <th>age</th>\n",
              "      <th>hand</th>\n",
              "      <th>religion</th>\n",
              "      <th>orientation</th>\n",
              "      <th>voted</th>\n",
              "      <th>married</th>\n",
              "      <th>familysize</th>\n",
              "      <th>ASD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>553</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>85</td>\n",
              "      <td>120</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>108</td>\n",
              "      <td>100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>43</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "      <td>139</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>640</td>\n",
              "      <td>216</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>176</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17</td>\n",
              "      <td>88</td>\n",
              "      <td>164</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20</td>\n",
              "      <td>53</td>\n",
              "      <td>112</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9</td>\n",
              "      <td>164</td>\n",
              "      <td>213</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>109</td>\n",
              "      <td>134</td>\n",
              "      <td>177</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f1bc8ee-4fdd-4604-9d13-8edf0b3542cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f1bc8ee-4fdd-4604-9d13-8edf0b3542cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f1bc8ee-4fdd-4604-9d13-8edf0b3542cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(train_target[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "OOCQl2sxQFoZ",
        "outputId": "9c03c3a6-b0be-4e26-9005-172b0a54e31b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    0\n",
              "5    1\n",
              "6    1\n",
              "7    1\n",
              "8    0\n",
              "9    0\n",
              "Name: nerdiness, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard Scaler"
      ],
      "metadata": {
        "id": "WwKQluIDTwqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standard scaler\n",
        "def scaler(dataset):\n",
        "  scaler = StandardScaler()\n",
        "  out = scaler.fit_transform(dataset)\n",
        "  return out"
      ],
      "metadata": {
        "id": "KCm3_jHBHyqB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # 평균 0, 분산 1을 갖도록 스케일 조정\n",
        "\n",
        "# # scaler = StandardScaler()\n",
        "# # scaler.fit(X_train)\n",
        "# # X_train_scaled = scaler.transform(X_train)\n",
        "# # X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # 조정된 데이터로 SVM 학습\n",
        "# svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# # 스케일 조정된 테스트 세트의 정확도\n",
        "# print(svm.score(X_test_scaled, y_test))"
      ],
      "metadata": {
        "id": "HkIz6whCQhie"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full data generate function\n",
        "def full_data(dataset):\n",
        "  full_data = pd.get_dummies(dataset, columns=['gender', 'hand', 'religion', 'orientation', 'voted', 'married', 'ASD'], drop_first=True)\n",
        "  full_data = scaler(full_data)\n",
        "  return full_data"
      ],
      "metadata": {
        "id": "fkyW1G3nHytb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(full_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "e6vUDzCZTkMU",
        "outputId": "e87fa9e3-6e82-4b81-be27-f361b0c2fcb7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<function __main__.full_data(dataset)>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature Engineering - MV data\n",
        "def MV_data(dataset):\n",
        "  MV_data = dataset.iloc[:, [1,2,3,4,5,7,8,9,10,11,12,13,15,16,17,19,20]]\n",
        "\n",
        "  for i in [3,7,10,16,4,11,17,9]:\n",
        "    MV_data['Q' + str(i)] = 6 - MV_data['Q' + str(i)]\n",
        "\n",
        "  MV_data['score'] = np.sum(MV_data, axis=1)\n",
        "\n",
        "  MV_data = scaler(MV_data)\n",
        "\n",
        "  return MV_data"
      ],
      "metadata": {
        "id": "rq5JVKurHyw6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# survey data - Q1~Q26\n",
        "def survey_data(dataset):\n",
        "  survey_data = dataset.iloc[:, 1:26]\n",
        "  survey_data = scaler(survey_data)\n",
        "  return survey_data"
      ],
      "metadata": {
        "id": "eoibaB4wHy0R"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pca data - maximized dimention about input data and decrese of dimention\n",
        "# input : survey data\n",
        "def pca_data(dataset):\n",
        "  poly = PolynomialFeatures(include_bias=False, degree=2)\n",
        "  poly_data = poly.fit_transform(dataset)\n",
        "\n",
        "  pca = PCA(n_components=50)\n",
        "  pca_data = pca.fit_transform(poly_data)\n",
        "  # pca_data = scaler(pca_data)\n",
        "  return pca_data"
      ],
      "metadata": {
        "id": "uKWe3vWgHy3Z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(MV_data)\n",
        "print(survey_data)\n",
        "print(pca_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6ruOTVVUNxF",
        "outputId": "d1ceddc9-7018-4a83-f0a5-8b70a81b13d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function MV_data at 0x7f89778abe60>\n",
            "<function survey_data at 0x7f89778ad3b0>\n",
            "<function pca_data at 0x7f89778ada70>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXlmkNdn_qQi",
        "outputId": "d1a470ed-c66b-44d6-cff2-28cd29e37dce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 개발\n",
        "- 모델은 각 데이터 셋 별로 3개씩 생성\n",
        "  - XGBoost\n",
        "  - LGBM\n",
        "  - RandomForestClassifier"
      ],
      "metadata": {
        "id": "WDgmf2MIIczQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 및 예측을 자동을 수행하는 함수를 생성\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "def model_fit_predict(dataset, targetdata, testset):\n",
        "  model1 = RandomForestClassifier()\n",
        "  model2 = XGBClassifier(n_estimators=2000, learning_rate=0.03, max_depth=20)\n",
        "  model3 = LGBMClassifier(n_estimators=2000, max_depth=20)\n",
        "  model4 = CatBoostClassifier(iterations=2, depth=7, learning_rate=0.03, \n",
        "                              loss_function='Logloss', verbose=True)\n",
        "\n",
        "\n",
        "  # for model in [model1, model2, model3]:\n",
        "  #   model.fit(dataset,targetdata)\n",
        "  \n",
        "  # fit\n",
        "  model1.fit(dataset,targetdata)\n",
        "  model2.fit(dataset,targetdata)\n",
        "  model3.fit(dataset,targetdata)\n",
        "  model4.fit(dataset,targetdata)\n",
        "    \n",
        "  # predict\n",
        "  pred1 = model1.predict(testset)\n",
        "  pred2 = model2.predict(testset)\n",
        "  pred3 = model3.predict(testset)\n",
        "  pred4 = model4.predict(testset)\n",
        "\n",
        "  pred_sum = pred1 + pred2 + pred3 + pred4\n",
        "\n",
        "  # hard voting ensemble\n",
        "  predict_final = []\n",
        "  for pred in pred_sum:\n",
        "    if pred > 2:\n",
        "      predict_final.append(1)\n",
        "    else:\n",
        "      predict_final.append(0)\n",
        "\n",
        "  return np.array(predict_final)"
      ],
      "metadata": {
        "id": "nq7vfJ5qIfoa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LdAKZeLMESct"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼파라미터 튜닝"
      ],
      "metadata": {
        "id": "STAk-ErGgiXH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGsDndZwgj9e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uhxvfNXighYd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 생성"
      ],
      "metadata": {
        "id": "YMpVF5kVIwsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 만들어내기\n",
        "full_data_train = full_data(train_input)\n",
        "full_data_test = full_data(test)\n",
        "\n",
        "MV_data_train = MV_data(train_input)\n",
        "MV_data_test = MV_data(test)\n",
        "\n",
        "survey_data_train = survey_data(train_input)\n",
        "survey_data_test = survey_data(test)\n",
        "\n",
        "pca_data_train = pca_data(survey_data_train)\n",
        "pca_data_test = pca_data(survey_data_test)\n",
        "\n",
        "# catboost_data_train = "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXEu9ln0IfvV",
        "outputId": "c8753a13-8db3-4b03-8c07-7782231d70bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 생성 1개씩 찍어내자"
      ],
      "metadata": {
        "id": "iYLYMzBfI44j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1_pred = model_fit_predict(full_data_train, train_target, full_data_test)"
      ],
      "metadata": {
        "id": "L2vk2IfnIf0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f90fbe-4ada-4748-95ac-7dc3d352f066"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6852862\ttotal: 57.1ms\tremaining: 57.1ms\n",
            "1:\tlearn: 0.6777591\ttotal: 65.9ms\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2_pred = model_fit_predict(MV_data_train, train_target, MV_data_test)"
      ],
      "metadata": {
        "id": "zSZHudjbIf5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54cf570b-e5a1-4a72-f137-a8408e30bae8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6878182\ttotal: 2.76ms\tremaining: 2.76ms\n",
            "1:\tlearn: 0.6828444\ttotal: 5.15ms\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3_pred = model_fit_predict(survey_data_train, train_target, survey_data_test)"
      ],
      "metadata": {
        "id": "G4hSKvqHI8jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774317a4-0c9e-4c7d-9ea4-1518dc581bc2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6856783\ttotal: 4.69ms\tremaining: 4.69ms\n",
            "1:\tlearn: 0.6781057\ttotal: 8.85ms\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4_pred = model_fit_predict(pca_data_train, train_target, pca_data_test)"
      ],
      "metadata": {
        "id": "zI612rr7I8nS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c0797b-d168-4a18-a156-0aba8ac2e60d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6867483\ttotal: 23.1ms\tremaining: 23.1ms\n",
            "1:\tlearn: 0.6803395\ttotal: 48.1ms\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #catboost\n",
        "# model5_pred = model_fit_predict(full_data_train, train_target, full_data_test)"
      ],
      "metadata": {
        "id": "vgo9V-XSClRA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 딥러닝 모델 추가"
      ],
      "metadata": {
        "id": "l--BWVj7JB22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# deep_model1 with full_data\n",
        "deep_model1 = keras.Sequential()\n",
        "deep_model1.add(keras.layers.Dense(128, activation='leaky_relu', input_shape=(84,)))\n",
        "deep_model1.add(keras.layers.Dropout(0.3))\n",
        "deep_model1.add(keras.layers.Dense(64, activation='leaky_relu'))\n",
        "deep_model1.add(keras.layers.Dropout(0.2))\n",
        "deep_model1.add(keras.layers.Dense(32, activation='leaky_relu'))\n",
        "deep_model1.add(keras.layers.Dense(16, activation='leaky_relu'))\n",
        "deep_model1.add(keras.layers.Dense(8, activation='leaky_relu'))\n",
        "deep_model1.add(keras.layers.Dense(8, activation='leaky_relu'))\n",
        "deep_model1.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# fit\n",
        "deep_model1.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n",
        "deep_model1.fit(full_data_train, train_target, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4pjedLxJEHV",
        "outputId": "f96826f1-3f01-4f49-d8ef-de1951531cb8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5722 - accuracy: 0.7083\n",
            "Epoch 2/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5470 - accuracy: 0.7262\n",
            "Epoch 3/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7303\n",
            "Epoch 4/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7359\n",
            "Epoch 5/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5303 - accuracy: 0.7353\n",
            "Epoch 6/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7360\n",
            "Epoch 7/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5195 - accuracy: 0.7435\n",
            "Epoch 8/200\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5156 - accuracy: 0.7471\n",
            "Epoch 9/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5105 - accuracy: 0.7489\n",
            "Epoch 10/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.7508\n",
            "Epoch 11/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.7513\n",
            "Epoch 12/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4982 - accuracy: 0.7534\n",
            "Epoch 13/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4943 - accuracy: 0.7585\n",
            "Epoch 14/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4910 - accuracy: 0.7602\n",
            "Epoch 15/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4931 - accuracy: 0.7587\n",
            "Epoch 16/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4875 - accuracy: 0.7603\n",
            "Epoch 17/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4882 - accuracy: 0.7632\n",
            "Epoch 18/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4798 - accuracy: 0.7669\n",
            "Epoch 19/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4794 - accuracy: 0.7692\n",
            "Epoch 20/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.7693\n",
            "Epoch 21/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4717 - accuracy: 0.7699\n",
            "Epoch 22/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4682 - accuracy: 0.7747\n",
            "Epoch 23/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4678 - accuracy: 0.7707\n",
            "Epoch 24/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4647 - accuracy: 0.7789\n",
            "Epoch 25/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.7818\n",
            "Epoch 26/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4594 - accuracy: 0.7813\n",
            "Epoch 27/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4578 - accuracy: 0.7820\n",
            "Epoch 28/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4510 - accuracy: 0.7868\n",
            "Epoch 29/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4475 - accuracy: 0.7876\n",
            "Epoch 30/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4472 - accuracy: 0.7861\n",
            "Epoch 31/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.7895\n",
            "Epoch 32/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4503 - accuracy: 0.7858\n",
            "Epoch 33/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4468 - accuracy: 0.7857\n",
            "Epoch 34/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4419 - accuracy: 0.7890\n",
            "Epoch 35/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4375 - accuracy: 0.7941\n",
            "Epoch 36/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4427 - accuracy: 0.7890\n",
            "Epoch 37/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4370 - accuracy: 0.7939\n",
            "Epoch 38/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4330 - accuracy: 0.7965\n",
            "Epoch 39/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4345 - accuracy: 0.7909\n",
            "Epoch 40/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4309 - accuracy: 0.7975\n",
            "Epoch 41/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4325 - accuracy: 0.7961\n",
            "Epoch 42/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4295 - accuracy: 0.7987\n",
            "Epoch 43/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4271 - accuracy: 0.8011\n",
            "Epoch 44/200\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4251 - accuracy: 0.8016\n",
            "Epoch 45/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4214 - accuracy: 0.8007\n",
            "Epoch 46/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4248 - accuracy: 0.8019\n",
            "Epoch 47/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4223 - accuracy: 0.8025\n",
            "Epoch 48/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4244 - accuracy: 0.8003\n",
            "Epoch 49/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4161 - accuracy: 0.8092\n",
            "Epoch 50/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4221 - accuracy: 0.8051\n",
            "Epoch 51/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4199 - accuracy: 0.8065\n",
            "Epoch 52/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4144 - accuracy: 0.8057\n",
            "Epoch 53/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4114 - accuracy: 0.8090\n",
            "Epoch 54/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4121 - accuracy: 0.8105\n",
            "Epoch 55/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4128 - accuracy: 0.8095\n",
            "Epoch 56/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8119\n",
            "Epoch 57/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4165 - accuracy: 0.8109\n",
            "Epoch 58/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4104 - accuracy: 0.8091\n",
            "Epoch 59/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4073 - accuracy: 0.8119\n",
            "Epoch 60/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4064 - accuracy: 0.8114\n",
            "Epoch 61/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4085 - accuracy: 0.8105\n",
            "Epoch 62/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4078 - accuracy: 0.8113\n",
            "Epoch 63/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4053 - accuracy: 0.8131\n",
            "Epoch 64/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4017 - accuracy: 0.8173\n",
            "Epoch 65/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.8139\n",
            "Epoch 66/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3988 - accuracy: 0.8173\n",
            "Epoch 67/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4023 - accuracy: 0.8135\n",
            "Epoch 68/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.8160\n",
            "Epoch 69/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3971 - accuracy: 0.8154\n",
            "Epoch 70/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3963 - accuracy: 0.8203\n",
            "Epoch 71/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3921 - accuracy: 0.8255\n",
            "Epoch 72/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.8205\n",
            "Epoch 73/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.4029 - accuracy: 0.8138\n",
            "Epoch 74/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8240\n",
            "Epoch 75/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3906 - accuracy: 0.8191\n",
            "Epoch 76/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3861 - accuracy: 0.8249\n",
            "Epoch 77/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8212\n",
            "Epoch 78/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3895 - accuracy: 0.8215\n",
            "Epoch 79/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3960 - accuracy: 0.8235\n",
            "Epoch 80/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3930 - accuracy: 0.8207\n",
            "Epoch 81/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8239\n",
            "Epoch 82/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3921 - accuracy: 0.8201\n",
            "Epoch 83/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3864 - accuracy: 0.8229\n",
            "Epoch 84/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3919 - accuracy: 0.8235\n",
            "Epoch 85/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3853 - accuracy: 0.8239\n",
            "Epoch 86/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3856 - accuracy: 0.8230\n",
            "Epoch 87/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3855 - accuracy: 0.8266\n",
            "Epoch 88/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.8269\n",
            "Epoch 89/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3801 - accuracy: 0.8281\n",
            "Epoch 90/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3788 - accuracy: 0.8289\n",
            "Epoch 91/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3822 - accuracy: 0.8249\n",
            "Epoch 92/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3827 - accuracy: 0.8253\n",
            "Epoch 93/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3807 - accuracy: 0.8303\n",
            "Epoch 94/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3808 - accuracy: 0.8247\n",
            "Epoch 95/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3751 - accuracy: 0.8321\n",
            "Epoch 96/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3849 - accuracy: 0.8279\n",
            "Epoch 97/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3810 - accuracy: 0.8285\n",
            "Epoch 98/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3738 - accuracy: 0.8334\n",
            "Epoch 99/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3856 - accuracy: 0.8264\n",
            "Epoch 100/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3791 - accuracy: 0.8280\n",
            "Epoch 101/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3821 - accuracy: 0.8272\n",
            "Epoch 102/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3790 - accuracy: 0.8276\n",
            "Epoch 103/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3761 - accuracy: 0.8283\n",
            "Epoch 104/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3742 - accuracy: 0.8280\n",
            "Epoch 105/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3763 - accuracy: 0.8274\n",
            "Epoch 106/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3772 - accuracy: 0.8308\n",
            "Epoch 107/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3774 - accuracy: 0.8284\n",
            "Epoch 108/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3751 - accuracy: 0.8301\n",
            "Epoch 109/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3673 - accuracy: 0.8347\n",
            "Epoch 110/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3705 - accuracy: 0.8335\n",
            "Epoch 111/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3745 - accuracy: 0.8301\n",
            "Epoch 112/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3686 - accuracy: 0.8317\n",
            "Epoch 113/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3689 - accuracy: 0.8327\n",
            "Epoch 114/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3699 - accuracy: 0.8329\n",
            "Epoch 115/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3731 - accuracy: 0.8305\n",
            "Epoch 116/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3756 - accuracy: 0.8283\n",
            "Epoch 117/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3675 - accuracy: 0.8373\n",
            "Epoch 118/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3704 - accuracy: 0.8351\n",
            "Epoch 119/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3656 - accuracy: 0.8374\n",
            "Epoch 120/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3663 - accuracy: 0.8381\n",
            "Epoch 121/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3736 - accuracy: 0.8319\n",
            "Epoch 122/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3663 - accuracy: 0.8339\n",
            "Epoch 123/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3692 - accuracy: 0.8343\n",
            "Epoch 124/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3720 - accuracy: 0.8330\n",
            "Epoch 125/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3650 - accuracy: 0.8356\n",
            "Epoch 126/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3656 - accuracy: 0.8373\n",
            "Epoch 127/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8401\n",
            "Epoch 128/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8360\n",
            "Epoch 129/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3615 - accuracy: 0.8387\n",
            "Epoch 130/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8353\n",
            "Epoch 131/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3645 - accuracy: 0.8350\n",
            "Epoch 132/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3612 - accuracy: 0.8387\n",
            "Epoch 133/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3665 - accuracy: 0.8367\n",
            "Epoch 134/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.8357\n",
            "Epoch 135/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3574 - accuracy: 0.8382\n",
            "Epoch 136/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3564 - accuracy: 0.8432\n",
            "Epoch 137/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3598 - accuracy: 0.8415\n",
            "Epoch 138/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3567 - accuracy: 0.8426\n",
            "Epoch 139/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3601 - accuracy: 0.8438\n",
            "Epoch 140/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3552 - accuracy: 0.8432\n",
            "Epoch 141/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3585 - accuracy: 0.8409\n",
            "Epoch 142/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8388\n",
            "Epoch 143/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3542 - accuracy: 0.8433\n",
            "Epoch 144/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3569 - accuracy: 0.8397\n",
            "Epoch 145/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3562 - accuracy: 0.8407\n",
            "Epoch 146/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3557 - accuracy: 0.8412\n",
            "Epoch 147/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3522 - accuracy: 0.8435\n",
            "Epoch 148/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3612 - accuracy: 0.8372\n",
            "Epoch 149/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3565 - accuracy: 0.8437\n",
            "Epoch 150/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3644 - accuracy: 0.8407\n",
            "Epoch 151/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3571 - accuracy: 0.8404\n",
            "Epoch 152/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3560 - accuracy: 0.8415\n",
            "Epoch 153/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3574 - accuracy: 0.8409\n",
            "Epoch 154/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3464 - accuracy: 0.8460\n",
            "Epoch 155/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3546 - accuracy: 0.8431\n",
            "Epoch 156/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3537 - accuracy: 0.8407\n",
            "Epoch 157/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3466 - accuracy: 0.8460\n",
            "Epoch 158/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3606 - accuracy: 0.8405\n",
            "Epoch 159/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3531 - accuracy: 0.8412\n",
            "Epoch 160/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3507 - accuracy: 0.8445\n",
            "Epoch 161/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3539 - accuracy: 0.8402\n",
            "Epoch 162/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3529 - accuracy: 0.8441\n",
            "Epoch 163/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3445 - accuracy: 0.8427\n",
            "Epoch 164/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3560 - accuracy: 0.8418\n",
            "Epoch 165/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3514 - accuracy: 0.8455\n",
            "Epoch 166/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3566 - accuracy: 0.8437\n",
            "Epoch 167/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3496 - accuracy: 0.8480\n",
            "Epoch 168/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3476 - accuracy: 0.8460\n",
            "Epoch 169/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3460 - accuracy: 0.8471\n",
            "Epoch 170/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3539 - accuracy: 0.8411\n",
            "Epoch 171/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3478 - accuracy: 0.8417\n",
            "Epoch 172/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3509 - accuracy: 0.8446\n",
            "Epoch 173/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3520 - accuracy: 0.8439\n",
            "Epoch 174/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3425 - accuracy: 0.8491\n",
            "Epoch 175/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3482 - accuracy: 0.8491\n",
            "Epoch 176/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3476 - accuracy: 0.8457\n",
            "Epoch 177/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8485\n",
            "Epoch 178/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3489 - accuracy: 0.8445\n",
            "Epoch 179/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.8488\n",
            "Epoch 180/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3462 - accuracy: 0.8483\n",
            "Epoch 181/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8507\n",
            "Epoch 182/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3455 - accuracy: 0.8466\n",
            "Epoch 183/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3467 - accuracy: 0.8469\n",
            "Epoch 184/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3361 - accuracy: 0.8515\n",
            "Epoch 185/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3457 - accuracy: 0.8459\n",
            "Epoch 186/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3446 - accuracy: 0.8483\n",
            "Epoch 187/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3400 - accuracy: 0.8525\n",
            "Epoch 188/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3459 - accuracy: 0.8497\n",
            "Epoch 189/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8445\n",
            "Epoch 190/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3401 - accuracy: 0.8539\n",
            "Epoch 191/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8499\n",
            "Epoch 192/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3444 - accuracy: 0.8509\n",
            "Epoch 193/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3408 - accuracy: 0.8475\n",
            "Epoch 194/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3414 - accuracy: 0.8514\n",
            "Epoch 195/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3523 - accuracy: 0.8457\n",
            "Epoch 196/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8493\n",
            "Epoch 197/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3373 - accuracy: 0.8479\n",
            "Epoch 198/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3379 - accuracy: 0.8507\n",
            "Epoch 199/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8462\n",
            "Epoch 200/200\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.3421 - accuracy: 0.8491\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88fa24df50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvj13RExWtzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(deep_model1.predict(full_data_test))[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7uNM41AJER1",
        "outputId": "9fd54d54-a413-494b-fcaa-22fd8104db35"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deep_model2 with _MV_data\n",
        "deep_model2 = keras.Sequential()\n",
        "deep_model2.add(keras.layers.Dense(64, activation='leaky_relu', input_shape=(18,)))\n",
        "deep_model2.add(keras.layers.Dropout(0.3))\n",
        "deep_model2.add(keras.layers.Dense(32, activation='leaky_relu'))\n",
        "deep_model2.add(keras.layers.Dropout(0.2))\n",
        "deep_model2.add(keras.layers.Dense(16, activation='leaky_relu'))\n",
        "deep_model2.add(keras.layers.Dense(8, activation='leaky_relu'))\n",
        "deep_model2.add(keras.layers.Dense(4, activation='leaky_relu'))\n",
        "deep_model2.add(keras.layers.Dense(2, activation='leaky_relu'))\n",
        "deep_model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# fit\n",
        "deep_model2.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n",
        "deep_model2.fit(MV_data_train, train_target, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSwqGdshJRr1",
        "outputId": "ff71f575-e5f6-44ff-c0ed-252289b57d71"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.6001 - accuracy: 0.6845\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5755 - accuracy: 0.7031\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5719 - accuracy: 0.7029\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7043\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7039\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5682 - accuracy: 0.7077\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5676 - accuracy: 0.7069\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5659 - accuracy: 0.7095\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5655 - accuracy: 0.7074\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5646 - accuracy: 0.7098\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7093\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5634 - accuracy: 0.7079\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.7103\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5627 - accuracy: 0.7106\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5614 - accuracy: 0.7117\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5611 - accuracy: 0.7138\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5616 - accuracy: 0.7105\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5619 - accuracy: 0.7114\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5618 - accuracy: 0.7109\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5595 - accuracy: 0.7153\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5585 - accuracy: 0.7152\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5599 - accuracy: 0.7135\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5595 - accuracy: 0.7164\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5596 - accuracy: 0.7173\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5585 - accuracy: 0.7139\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5593 - accuracy: 0.7156\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7151\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5565 - accuracy: 0.7169\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5572 - accuracy: 0.7160\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5574 - accuracy: 0.7161\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5582 - accuracy: 0.7181\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5563 - accuracy: 0.7172\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5568 - accuracy: 0.7196\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5576 - accuracy: 0.7148\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7141\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5555 - accuracy: 0.7183\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5547 - accuracy: 0.7157\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5543 - accuracy: 0.7159\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5549 - accuracy: 0.7167\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7170\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5528 - accuracy: 0.7223\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7175\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5551 - accuracy: 0.7174\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5540 - accuracy: 0.7201\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5541 - accuracy: 0.7193\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5543 - accuracy: 0.7175\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5512 - accuracy: 0.7203\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5533 - accuracy: 0.7203\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5532 - accuracy: 0.7201\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5514 - accuracy: 0.7183\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5536 - accuracy: 0.7199\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7161\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7191\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5516 - accuracy: 0.7193\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5516 - accuracy: 0.7174\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5536 - accuracy: 0.7196\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5537 - accuracy: 0.7221\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5517 - accuracy: 0.7209\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5523 - accuracy: 0.7191\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5533 - accuracy: 0.7199\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5506 - accuracy: 0.7205\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7199\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5516 - accuracy: 0.7187\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5522 - accuracy: 0.7211\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7227\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5528 - accuracy: 0.7185\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5493 - accuracy: 0.7243\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5518 - accuracy: 0.7215\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5495 - accuracy: 0.7221\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7230\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5495 - accuracy: 0.7199\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5503 - accuracy: 0.7226\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7230\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7252\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7233\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5500 - accuracy: 0.7209\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5500 - accuracy: 0.7239\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7253\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7228\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.7246\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7223\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7261\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7231\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7245\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5467 - accuracy: 0.7249\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5490 - accuracy: 0.7265\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5504 - accuracy: 0.7213\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5516 - accuracy: 0.7227\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5473 - accuracy: 0.7241\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5487 - accuracy: 0.7229\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7253\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5488 - accuracy: 0.7243\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7258\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5483 - accuracy: 0.7239\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7255\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7267\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.7267\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5494 - accuracy: 0.7244\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7251\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7229\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88f80bca10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deep_model3 with survey_data\n",
        "deep_model3 = keras.Sequential()\n",
        "deep_model3.add(keras.layers.Dense(16, activation='leaky_relu', input_shape=(25,)))\n",
        "deep_model2.add(keras.layers.Dropout(0.2))\n",
        "deep_model3.add(keras.layers.Dense(8, activation='leaky_relu'))\n",
        "deep_model3.add(keras.layers.Dense(4, activation='leaky_relu'))\n",
        "deep_model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# fit\n",
        "deep_model3.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n",
        "deep_model3.fit(survey_data_train, train_target, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WNMT4DBJR0m",
        "outputId": "f292b72a-a1fb-43e7-a5de-a4aa2f5eeb93"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5761 - accuracy: 0.6981\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 0s 984us/step - loss: 0.5506 - accuracy: 0.7189\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 0s 982us/step - loss: 0.5464 - accuracy: 0.7237\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7253\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7267\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7310\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7311\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7334\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 0s 963us/step - loss: 0.5349 - accuracy: 0.7355\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 0s 957us/step - loss: 0.5343 - accuracy: 0.7339\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 0s 958us/step - loss: 0.5331 - accuracy: 0.7363\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 0s 965us/step - loss: 0.5320 - accuracy: 0.7347\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 0s 925us/step - loss: 0.5310 - accuracy: 0.7359\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 0s 952us/step - loss: 0.5305 - accuracy: 0.7375\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5293 - accuracy: 0.7377\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 0s 983us/step - loss: 0.5286 - accuracy: 0.7373\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 0s 963us/step - loss: 0.5280 - accuracy: 0.7376\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 0s 969us/step - loss: 0.5276 - accuracy: 0.7389\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 0s 966us/step - loss: 0.5265 - accuracy: 0.7385\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 0s 983us/step - loss: 0.5261 - accuracy: 0.7390\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 0s 968us/step - loss: 0.5256 - accuracy: 0.7407\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 0s 954us/step - loss: 0.5246 - accuracy: 0.7403\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 0s 979us/step - loss: 0.5243 - accuracy: 0.7410\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 0s 964us/step - loss: 0.5236 - accuracy: 0.7393\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 0s 992us/step - loss: 0.5229 - accuracy: 0.7419\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 0s 964us/step - loss: 0.5227 - accuracy: 0.7430\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 0s 984us/step - loss: 0.5220 - accuracy: 0.7425\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 0s 953us/step - loss: 0.5219 - accuracy: 0.7429\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7411\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 0s 942us/step - loss: 0.5209 - accuracy: 0.7421\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 0s 993us/step - loss: 0.5205 - accuracy: 0.7454\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 0s 945us/step - loss: 0.5201 - accuracy: 0.7437\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7449\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 0s 962us/step - loss: 0.5196 - accuracy: 0.7434\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 0s 967us/step - loss: 0.5194 - accuracy: 0.7441\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 0s 999us/step - loss: 0.5190 - accuracy: 0.7445\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 0s 992us/step - loss: 0.5190 - accuracy: 0.7451\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 0s 964us/step - loss: 0.5182 - accuracy: 0.7464\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 0s 984us/step - loss: 0.5180 - accuracy: 0.7454\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 0s 962us/step - loss: 0.5173 - accuracy: 0.7463\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 0s 960us/step - loss: 0.5178 - accuracy: 0.7455\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 0s 984us/step - loss: 0.5171 - accuracy: 0.7452\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 0s 980us/step - loss: 0.5168 - accuracy: 0.7471\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7439\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7466\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7482\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7478\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7469\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7479\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5149 - accuracy: 0.7482\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88f7d89b10>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deep_model4 with pca_data\n",
        "deep_model4 = keras.Sequential()\n",
        "deep_model4.add(keras.layers.Dense(32, activation='leaky_relu', input_shape=(50,)))\n",
        "deep_model4.add(keras.layers.Dropout(0.2))\n",
        "deep_model4.add(keras.layers.Dense(16, activation='leaky_relu'))\n",
        "deep_model4.add(keras.layers.Dense(8, activation='leaky_relu'))\n",
        "deep_model4.add(keras.layers.Dense(4, activation='leaky_relu'))\n",
        "deep_model4.add(keras.layers.Dense(2, activation='leaky_relu'))\n",
        "deep_model4.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# fit\n",
        "deep_model4.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n",
        "deep_model4.fit(pca_data_train, train_target, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWonmz1PJYKK",
        "outputId": "ab4415ed-84e5-42ce-d103-93c6c701a9bb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.6340 - accuracy: 0.6383\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5791 - accuracy: 0.6911\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5673 - accuracy: 0.6979\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5617 - accuracy: 0.7011\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5566 - accuracy: 0.7069\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.7061\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7106\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7109\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5468 - accuracy: 0.7123\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7129\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7144\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7131\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7156\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7165\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7174\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.7226\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7215\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7215\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7257\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7225\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5305 - accuracy: 0.7270\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7265\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5294 - accuracy: 0.7270\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5317 - accuracy: 0.7269\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5299 - accuracy: 0.7284\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5271 - accuracy: 0.7285\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5274 - accuracy: 0.7300\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7249\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5267 - accuracy: 0.7297\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5266 - accuracy: 0.7279\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5246 - accuracy: 0.7285\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5235 - accuracy: 0.7313\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5225 - accuracy: 0.7288\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5245 - accuracy: 0.7289\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5232 - accuracy: 0.7293\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5219 - accuracy: 0.7289\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5224 - accuracy: 0.7325\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5203 - accuracy: 0.7343\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5206 - accuracy: 0.7293\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5208 - accuracy: 0.7340\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5203 - accuracy: 0.7332\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5190 - accuracy: 0.7348\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5189 - accuracy: 0.7351\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5170 - accuracy: 0.7333\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5160 - accuracy: 0.7373\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5164 - accuracy: 0.7343\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5154 - accuracy: 0.7379\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5140 - accuracy: 0.7378\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5138 - accuracy: 0.7394\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.5152 - accuracy: 0.7347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88f7c1f2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow import keras\n",
        "\n",
        "# # deep_model5 with full_data\n",
        "# deep_model5 = keras.Sequential()\n",
        "# deep_model5.add(keras.layers.Dense(128, activation='elu', input_shape=(84,)))\n",
        "# deep_model5.add(keras.layers.Dropout(0.3))\n",
        "# deep_model5.add(keras.layers.Dense(64, activation='elu'))\n",
        "# deep_model5.add(keras.layers.Dropout(0.3))\n",
        "# deep_model5.add(keras.layers.Dense(32, activation='elu'))\n",
        "# deep_model5.add(keras.layers.Dense(16, activation='elu'))\n",
        "# deep_model5.add(keras.layers.Dense(8, activation='elu'))\n",
        "# deep_model5.add(keras.layers.Dense(4, activation='elu'))\n",
        "# deep_model5.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# # fit\n",
        "# deep_model5.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n",
        "# deep_model5.fit(full_data_train, train_target, epochs=200)"
      ],
      "metadata": {
        "id": "L24l-FyVDYCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensemble\n",
        "def deep_result():\n",
        "  final_pred = []\n",
        "  preds = np.round(deep_model1.predict(full_data_test)) + np.round(deep_model2.predict(MV_data_test)) + np.round(deep_model3.predict(survey_data_test)) \n",
        "  + np.round(deep_model4.predict(pca_data_test))\n",
        "\n",
        "  for pred in preds:\n",
        "    if pred >= 2:\n",
        "      final_pred.append(1)\n",
        "    else:\n",
        "      final_pred.append(0)\n",
        "  \n",
        "  return np.array(final_pred)"
      ],
      "metadata": {
        "id": "5huVLfZtJYSS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deep_result = deep_result()"
      ],
      "metadata": {
        "id": "p3B6Q4WCJYYP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deep_result[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plNHEzvjJYhG",
        "outputId": "6f5af68b-a84a-43f0-fab6-7b749ef19a4b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 찍어낸 모델 테스트"
      ],
      "metadata": {
        "id": "vi66dLpsJpEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델이 예측한 값들을 찍어보는 코드\n",
        "\n",
        "# 일단 model4는 당시 사용을 안해서 일단은 주석처리를 해 두었다.\n",
        "print(model1_pred[:10])\n",
        "print(model2_pred[:10])\n",
        "print(model3_pred[:10])\n",
        "print(model4_pred[:10])\n",
        "# print(model5_pred[:10])  #이게 catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aCzpJU_JhPQ",
        "outputId": "e5b4c3b2-842a-485e-e33d-4b4a8f4ec6b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 1 1 0 1 1 0 0]\n",
            "[0 1 1 1 1 0 1 1 1 0]\n",
            "[0 1 1 1 1 0 1 1 0 0]\n",
            "[1 1 1 0 1 0 1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝 예측 모델 deep_model1만 사용했다.\n",
        "# 딥러닝 모델을 사용하고 싶다면 다른 것들을 추가해도 됩니다.\n",
        "deep_model1_pred = np.round(deep_model1.predict(full_data_test))\n",
        "deep_model1_pred = deep_model1_pred.reshape(-1)"
      ],
      "metadata": {
        "id": "tkUXVy2NXoSx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model1_pred + model2_pred + model3_pred + model4_pred #+ model5_pred"
      ],
      "metadata": {
        "id": "_lW7liKBJzGm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W46UAuyVJzUD",
        "outputId": "6de91d11-b13b-4863-a8df-b2b36d1ea349"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 4, ..., 3, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 모델의 결정을 위한 앙상블 학습\n",
        "# hard voting ensemble\n",
        "predict_final = []\n",
        "for pred in preds:\n",
        "  if pred >= 1.5:\n",
        "    predict_final.append(1)\n",
        "  else:\n",
        "    predict_final.append(0)\n",
        "\n",
        "result = np.array(predict_final)"
      ],
      "metadata": {
        "id": "w1r16ZpxJzZJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # soft voting ensemble 근데 이 모델에서 soft voting이 가능한가\n",
        "# predict_final2 = []\n",
        "# for pred in preds:\n",
        "#   if pred/3 >= 0.6:\n",
        "#     predict_final2.append(1)\n",
        "#   else:\n",
        "#     predict_final2.append(0)\n",
        "\n",
        "# result2 = np.array(predict_final2)"
      ],
      "metadata": {
        "id": "oHyBW7gTWr-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼파라미터 튜닝"
      ],
      "metadata": {
        "id": "AZYmXJezbfne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# params = {'min_impurity_decrease':np.arrange(0.0001, 0,001, 0.0001), 'max_depth': range(5,20,1), 'min_samples_split':range(2.100,10)}\n",
        "# dtree = DecisionTreeClassifier()\n",
        "\n",
        "# grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)\n",
        "# grid_search(params={'n_estimators':[100,200,400,800,1600,2400]})\n",
        "\n",
        "rmse_scores = []\n",
        "estimators = []\n",
        "\n",
        "rf = RandomForestRegressor(warm_start=True, n_jobs=-1, random_state=2)\n",
        "est=10\n",
        "\n",
        "# for i in range(21):\n",
        "#   rf.set_params(n_estimators=set)\n",
        "#   rf.fit(model1_pred, test)\n",
        "#   rmse = mean_squared_error(model1_pred, rf.predict(test), squared=False)\n",
        "#   rmse_scores.append(rmse)\n",
        "#   estimators.append(est)\n",
        "\n",
        "#   est +=25\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.plot(estimators, rmse_scores)\n",
        "plt.xlabel('Number of Trees')\n",
        "plt.ylabel('Rmse')\n",
        "plt.title('Random Forest', fontsize=15)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "35SQlyFSbetE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 성능 검사"
      ],
      "metadata": {
        "id": "O5m1cvBcaPHv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79blDpY3aQ7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yK7xyfZFpWcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(pred_sum)"
      ],
      "metadata": {
        "id": "Ts4R4i_xqKdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 제출 파일 생성"
      ],
      "metadata": {
        "id": "QUBmVZ6HSUnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출 파일 생성\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['nerdiness'] = result\n",
        "\n",
        "# 생성된 CSV 파일 저장하는 코드\n",
        "# 코랩에서 작업시 작업 디렉터리에 생성되며 이를 로컬로 다운 받아 제출을 해 주어야 한다.\n",
        "submission.to_csv(\"submission_yk6.csv\", index = False)"
      ],
      "metadata": {
        "id": "zwpqAHSpJziB"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1k2Q7Y8EST4I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}