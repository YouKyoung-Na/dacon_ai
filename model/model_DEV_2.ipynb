{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_DEV_2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1HasenOaTE7TeITrBg5f31CZquUmobA7a","authorship_tag":"ABX9TyPKjGJs+l9j7AGwJBtZ54Bm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 데이터 셋 생성을 위한 코드"],"metadata":{"id":"Yal1Kv2VffLc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftEr0QfcUtdw"},"outputs":[],"source":["# library import \n","# 필요한 라이브러리들 입니다.\n","# 코드 실행전에 임포트를 진행해주세요\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","source":["# data read\n","# data read는 드라이브 마운트가 되어있기 때문에 각자의 경로로 수정해 주셔야 합니다.\n","train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DACON/train.csv\")\n","test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DACON/test.csv\")"],"metadata":{"id":"Gp89QMVMU-ZQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 데이터 생성\n","모델에게 주어지는 데이터는 크게 4개를 생성 했습니다.  \n","자세한 내용은 주석 참고 부탁드려요"],"metadata":{"id":"5IIfHsDHztiZ"}},{"cell_type":"code","source":["# missing value processing\n","# median\n","# 결측치를 처리하기 위해서는 여러가지 방법이 있는데 그중 median(중간값)을 이용해야합니다.\n","# 평균 또는 다른 전처리 방법이 있다면 자유롭게 골라서 넣어주셔도 될 것 같아요.\n","train.fillna(train.median(), inplace=True)\n","test.fillna(train.median(), inplace=True)\n","\n","# contry 열 삭제\n","# country 열은 따로 처리하기 힘들어서 그냥 제외를 했습니다.\n","train.drop(['country'], axis=1, inplace=True)\n","test.drop(['country'], axis=1, inplace=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIMUU-K-VQnK","executionInfo":{"status":"ok","timestamp":1661214800466,"user_tz":-540,"elapsed":400,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"outputId":"94eaf25c-e753-4f8a-cff1-7a940364eed0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n","  after removing the cwd from sys.path.\n"]}]},{"cell_type":"code","source":["# train_data_split\n","# train_data에는 input 데이터와 target 데이터가 나누어져 있기 때문에 쪼개주는 작업이 필요합니다.\n","train_input = train.iloc[:, :-1]\n","train_target = train.iloc[:, -1]"],"metadata":{"id":"-rG4FFd5-Tzi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# standard scaler\n","# 정규화를 한번에 하기위한 과정을 함수로 적용하였습니다.\n","def scaler(dataset):\n","  scaler = StandardScaler()\n","  out = scaler.fit_transform(dataset)\n","  return out"],"metadata":{"id":"UZ8FB25oe3h3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# full data generate function\n","# 저희에게 주어진 전체 데이터를 이용합니다.\n","# 크게 수정해야할 부분은 없지만 범주형 데이터에 대해서는 원 핫 인코딩을 이용해서 이진 값으로 만들어야 할 것 같아 처리를 따로 진행햐였습니다.\n","def full_data(dataset):\n","  full_data = pd.get_dummies(dataset, columns=['gender', 'hand', 'religion', 'orientation', 'voted', 'married', 'ASD'], drop_first=True)\n","  full_data = scaler(full_data)\n","  return full_data"],"metadata":{"id":"jjo-cVSEVpTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# feature Engineering - MV data\n","# 마키아벨리즘 테스트를 수행하기 위해서 연관성 있는 해당 셀을 추출하여 데이터 생성(특성공학 : feature enginearing 을 진행을 합니다)\n","# 따로 처리를 해본 결과 별로 모델 성능 개선에는 도움이 된것 같지는 않아요.\n","def MV_data(dataset):\n","  MV_data = dataset.iloc[:, [1,2,3,4,5,7,8,9,10,11,12,13,15,16,17,19,20]]\n","\n","  for i in [3,7,10,16,4,11,17,9]:\n","    MV_data['Q' + str(i)] = 6 - MV_data['Q' + str(i)]\n","\n","  MV_data['score'] = np.sum(MV_data, axis=1)\n","\n","  MV_data = scaler(MV_data)\n","\n","  return MV_data"],"metadata":{"id":"K6NieJQGbzO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# survey data - Q1~Q26\n","# 일반적인 설문데이터 입니다 Q1 ~ Q26 까지의 데이터를 사용하였습니다.\n","def survey_data(dataset):\n","  survey_data = dataset.iloc[:, 1:26]\n","  survey_data = scaler(survey_data)\n","  return survey_data"],"metadata":{"id":"IFCakbCKcegB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pca data \n","# 데이터를 함수를 이용해서 생성을 한 후 차원 축소 알고리즘(pca)를 이용해서 처리를 했습니다.\n","# 주의해야할 부분으로는 pca데이터를 만들 때는 datase으로 바로 윗 셀에 있는 survey 데이터를 집어넣어 주셔야 합니다.\n","# input : survey data\n","def pca_data(dataset):\n","  poly = PolynomialFeatures(include_bias=False, degree=2)\n","  poly_data = poly.fit_transform(dataset)\n","\n","  pca = PCA(n_components=50)\n","  pca_data = pca.fit_transform(poly_data)\n","  # pca_data = scaler(pca_data)\n","  return pca_data"],"metadata":{"id":"iluDY3p1czdW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 개발\n","\n","- 모델은 각 데이터 셋 별로 3개씩 생성(모델 1개의 집단에 3개의 모델이 앙상블되어있음)\n","- XGBoost\n","- LGBM\n","- RandomForestClassifier\n","\n","현재 데이터셋은 4개가 준비된 상태  \n","각각의 데이터셋을 가지고 모델 군집 4개를 생성할 예정"],"metadata":{"id":"vwtlYGcn3hNw"}},{"cell_type":"code","source":["# 모델 생성 및 예측을 자동을 수행하는 함수를 생성\n","# 아래 코드는 함수를 이용해서 모델 생성 및 예측을 한번에 해주는 코드입니다.\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","\n","def model_fit_predict(dataset, targetdata, testset):\n","\n","  # 여기 들어가 있는 모델은 최적화가 이루어지지 않은 데이터들 입니다.\n","  # 각각의 데이터와 모델들에 대해서 하이퍼파라미터최적화를 진행해 주세요!(진짜 할 수 있는 마지막 방법입니다.)\n","\n","  model1 = RandomForestClassifier()\n","  model2 = XGBClassifier(n_estimators=2000, learning_rate=0.07, max_depth=16)\n","  model3 = LGBMClassifier(n_estimators=2000, max_depth=16)\n","\n","\n","  # for model in [model1, model2, model3]:\n","  #   model.fit(dataset,targetdata)\n","  \n","  # fit\n","  model1.fit(dataset,targetdata)\n","  model2.fit(dataset,targetdata)\n","  model3.fit(dataset,targetdata)\n","    \n","  # predict\n","  pred1 = model1.predict(testset)\n","  pred2 = model2.predict(testset)\n","  pred3 = model3.predict(testset)\n","\n","  pred_sum = pred1 + pred2 + pred3\n","\n","  # hard voting ensemble\n","  # 앙상블 모델은 sklearn의 voting 방법을 이용한 것이 아니라, 직접 코드로 구현한다.(이정도는..)\n","  # 1.5 이상이 된다면 1로 예측을 한다.(한개의 모델 집단에 3개의 모델이 들어 있으니까)\n","  predict_final = []\n","  for pred in pred_sum:\n","    if pred > 1.5:\n","      predict_final.append(1)\n","    else:\n","      predict_final.append(0)\n","\n","  return np.array(predict_final) # 예측한 결과를 리턴한다."],"metadata":{"id":"HsmwsqHU3i_V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## model 생성"],"metadata":{"id":"H8e-l3qo_R6x"}},{"cell_type":"code","source":["# 데이터 만들어내기\n","# 아까 데이터 셋을 정제하는 함수를 이용해서 진짜 데이터를 만들어 준다.\n","# warning 뭐시기가 뜨는데.. 그냥 무시해도 될 듯 하다. 어차피 데이터 셋은 잘 생성이 된다.\n","full_data_train = full_data(train_input)\n","full_data_test = full_data(test)\n","\n","MV_data_train = MV_data(train_input)\n","MV_data_test = MV_data(test)\n","\n","survey_data_train = survey_data(train_input)\n","survey_data_test = survey_data(test)\n","\n","pca_data_train = pca_data(survey_data_train)\n","pca_data_test = pca_data(survey_data_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jM_N4DoD_Uaa","executionInfo":{"status":"ok","timestamp":1661223251588,"user_tz":-540,"elapsed":5900,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"outputId":"7e3c2122-f61f-463e-9952-bda51cd3a322"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"markdown","source":["### 모델 생성 1개씩 찍어내자"],"metadata":{"id":"VtNGSsRGBoVZ"}},{"cell_type":"code","source":["model1_pred = model_fit_predict(full_data_train, train_target, full_data_test)"],"metadata":{"id":"E7DZofxpArk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2_pred = model_fit_predict(MV_data_train, train_target, MV_data_test)"],"metadata":{"id":"PEB5KtrpGJZW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model3_pred = model_fit_predict(survey_data_train, train_target, survey_data_test)"],"metadata":{"id":"-FiFUwWBFnvv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model4_pred = model_fit_predict(pca_data_train, train_target, pca_data_test)"],"metadata":{"id":"JEkjYqRXE9SW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 딥러닝 모델 추가\n","- 사실 앙상블 모델에 딥러닝을 추가하고 싶었는데(추가를 해봤는데), 그렇게 좋은 성능을 보이지는 못했다.\n","- 따라서 딥러닝 모델을 생성해 내는 것 보다. 그냥 하이퍼파라미터 튜닝을 하는 방법이 더 도움이 될 것으로 판단된다.\n","- 일단, 아래 모델들은 각 데이터 셋에 맞추어서 모델을 생성 해 본 것들이다.\n","- 사실 원래 코드는 파이토치를 이용해서 작성했지만, 너무 신경써야할 부분들이 많아서 keras로 변경했다.(이정도 선형모델을 짜는데에는 케라스가 짱인듯)"],"metadata":{"id":"KgT4GDxheIhG"}},{"cell_type":"code","source":["from tensorflow import keras\n","\n","# deep_model1 with full_data\n","deep_model1 = keras.Sequential()\n","deep_model1.add(keras.layers.Dense(128, activation='leaky_relu', input_shape=(84,)))\n","deep_model1.add(keras.layers.Dropout(0.3))\n","deep_model1.add(keras.layers.Dense(64, activation='leaky_relu'))\n","deep_model1.add(keras.layers.Dropout(0.3))\n","deep_model1.add(keras.layers.Dense(32, activation='leaky_relu'))\n","deep_model1.add(keras.layers.Dense(16, activation='leaky_relu'))\n","deep_model1.add(keras.layers.Dense(8, activation='leaky_relu'))\n","deep_model1.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","# fit\n","deep_model1.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n","deep_model1.fit(full_data_train, train_target, epochs=200)"],"metadata":{"id":"1GhI4g71eK8_","executionInfo":{"status":"ok","timestamp":1661215981468,"user_tz":-540,"elapsed":270954,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"014df740-7ce7-4843-c316-6a0df1a22d63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","469/469 [==============================] - 3s 4ms/step - loss: 0.5762 - accuracy: 0.7030\n","Epoch 2/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5465 - accuracy: 0.7227\n","Epoch 3/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7318\n","Epoch 4/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7359\n","Epoch 5/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7372\n","Epoch 6/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7427\n","Epoch 7/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7449\n","Epoch 8/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.7462\n","Epoch 9/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5140 - accuracy: 0.7481\n","Epoch 10/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7474\n","Epoch 11/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5085 - accuracy: 0.7519\n","Epoch 12/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7511\n","Epoch 13/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7578\n","Epoch 14/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4996 - accuracy: 0.7566\n","Epoch 15/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4942 - accuracy: 0.7614\n","Epoch 16/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.7655\n","Epoch 17/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7642\n","Epoch 18/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7683\n","Epoch 19/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.7678\n","Epoch 20/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4796 - accuracy: 0.7699\n","Epoch 21/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4783 - accuracy: 0.7720\n","Epoch 22/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4724 - accuracy: 0.7750\n","Epoch 23/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.7693\n","Epoch 24/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.7761\n","Epoch 25/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4673 - accuracy: 0.7785\n","Epoch 26/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.7783\n","Epoch 27/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7817\n","Epoch 28/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4627 - accuracy: 0.7793\n","Epoch 29/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4597 - accuracy: 0.7831\n","Epoch 30/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4613 - accuracy: 0.7791\n","Epoch 31/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.7843\n","Epoch 32/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4593 - accuracy: 0.7814\n","Epoch 33/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4505 - accuracy: 0.7887\n","Epoch 34/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.7861\n","Epoch 35/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4513 - accuracy: 0.7863\n","Epoch 36/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.7892\n","Epoch 37/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.7875\n","Epoch 38/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4402 - accuracy: 0.7924\n","Epoch 39/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.7903\n","Epoch 40/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4414 - accuracy: 0.7907\n","Epoch 41/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4382 - accuracy: 0.7954\n","Epoch 42/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.7971\n","Epoch 43/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4363 - accuracy: 0.7959\n","Epoch 44/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4337 - accuracy: 0.7975\n","Epoch 45/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4366 - accuracy: 0.7940\n","Epoch 46/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4386 - accuracy: 0.7959\n","Epoch 47/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4325 - accuracy: 0.8006\n","Epoch 48/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4365 - accuracy: 0.7920\n","Epoch 49/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4316 - accuracy: 0.7968\n","Epoch 50/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4349 - accuracy: 0.7983\n","Epoch 51/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.4283 - accuracy: 0.8043\n","Epoch 52/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4270 - accuracy: 0.8012\n","Epoch 53/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.8026\n","Epoch 54/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.8045\n","Epoch 55/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4292 - accuracy: 0.8009\n","Epoch 56/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.8015\n","Epoch 57/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4263 - accuracy: 0.8003\n","Epoch 58/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4195 - accuracy: 0.8055\n","Epoch 59/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.8033\n","Epoch 60/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4170 - accuracy: 0.8053\n","Epoch 61/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.8055\n","Epoch 62/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4186 - accuracy: 0.8071\n","Epoch 63/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4206 - accuracy: 0.8082\n","Epoch 64/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4197 - accuracy: 0.8092\n","Epoch 65/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4166 - accuracy: 0.8088\n","Epoch 66/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4171 - accuracy: 0.8084\n","Epoch 67/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4148 - accuracy: 0.8077\n","Epoch 68/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4212 - accuracy: 0.8039\n","Epoch 69/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4127 - accuracy: 0.8119\n","Epoch 70/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8108\n","Epoch 71/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4137 - accuracy: 0.8089\n","Epoch 72/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4074 - accuracy: 0.8142\n","Epoch 73/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4133 - accuracy: 0.8107\n","Epoch 74/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4095 - accuracy: 0.8137\n","Epoch 75/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4099 - accuracy: 0.8141\n","Epoch 76/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4110 - accuracy: 0.8077\n","Epoch 77/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4069 - accuracy: 0.8114\n","Epoch 78/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4054 - accuracy: 0.8101\n","Epoch 79/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4081 - accuracy: 0.8091\n","Epoch 80/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4069 - accuracy: 0.8153\n","Epoch 81/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8118\n","Epoch 82/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4026 - accuracy: 0.8173\n","Epoch 83/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4084 - accuracy: 0.8154\n","Epoch 84/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4048 - accuracy: 0.8121\n","Epoch 85/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8142\n","Epoch 86/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4029 - accuracy: 0.8148\n","Epoch 87/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8145\n","Epoch 88/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3978 - accuracy: 0.8174\n","Epoch 89/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4062 - accuracy: 0.8158\n","Epoch 90/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3982 - accuracy: 0.8157\n","Epoch 91/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3998 - accuracy: 0.8177\n","Epoch 92/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3949 - accuracy: 0.8213\n","Epoch 93/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3991 - accuracy: 0.8192\n","Epoch 94/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8179\n","Epoch 95/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3951 - accuracy: 0.8207\n","Epoch 96/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8194\n","Epoch 97/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3946 - accuracy: 0.8205\n","Epoch 98/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3958 - accuracy: 0.8208\n","Epoch 99/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3945 - accuracy: 0.8230\n","Epoch 100/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8198\n","Epoch 101/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8181\n","Epoch 102/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3988 - accuracy: 0.8193\n","Epoch 103/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3938 - accuracy: 0.8201\n","Epoch 104/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3930 - accuracy: 0.8194\n","Epoch 105/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3921 - accuracy: 0.8209\n","Epoch 106/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3916 - accuracy: 0.8218\n","Epoch 107/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3928 - accuracy: 0.8200\n","Epoch 108/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3880 - accuracy: 0.8234\n","Epoch 109/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3913 - accuracy: 0.8249\n","Epoch 110/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3879 - accuracy: 0.8211\n","Epoch 111/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8221\n","Epoch 112/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3868 - accuracy: 0.8247\n","Epoch 113/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3900 - accuracy: 0.8209\n","Epoch 114/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3936 - accuracy: 0.8191\n","Epoch 115/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3888 - accuracy: 0.8269\n","Epoch 116/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3942 - accuracy: 0.8208\n","Epoch 117/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3935 - accuracy: 0.8192\n","Epoch 118/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3883 - accuracy: 0.8235\n","Epoch 119/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3877 - accuracy: 0.8237\n","Epoch 120/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3867 - accuracy: 0.8251\n","Epoch 121/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3867 - accuracy: 0.8240\n","Epoch 122/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3835 - accuracy: 0.8288\n","Epoch 123/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3847 - accuracy: 0.8269\n","Epoch 124/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3859 - accuracy: 0.8263\n","Epoch 125/200\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3846 - accuracy: 0.8253\n","Epoch 126/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.8233\n","Epoch 127/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3838 - accuracy: 0.8267\n","Epoch 128/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3995 - accuracy: 0.8251\n","Epoch 129/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3826 - accuracy: 0.8283\n","Epoch 130/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3846 - accuracy: 0.8259\n","Epoch 131/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3820 - accuracy: 0.8268\n","Epoch 132/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3795 - accuracy: 0.8298\n","Epoch 133/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3785 - accuracy: 0.8331\n","Epoch 134/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3798 - accuracy: 0.8261\n","Epoch 135/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3774 - accuracy: 0.8289\n","Epoch 136/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.8279\n","Epoch 137/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3863 - accuracy: 0.8246\n","Epoch 138/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3845 - accuracy: 0.8264\n","Epoch 139/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3802 - accuracy: 0.8331\n","Epoch 140/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8343\n","Epoch 141/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8283\n","Epoch 142/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3788 - accuracy: 0.8310\n","Epoch 143/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3814 - accuracy: 0.8256\n","Epoch 144/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8299\n","Epoch 145/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3809 - accuracy: 0.8271\n","Epoch 146/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3737 - accuracy: 0.8317\n","Epoch 147/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3777 - accuracy: 0.8344\n","Epoch 148/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8329\n","Epoch 149/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3710 - accuracy: 0.8333\n","Epoch 150/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3748 - accuracy: 0.8309\n","Epoch 151/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3728 - accuracy: 0.8330\n","Epoch 152/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3731 - accuracy: 0.8337\n","Epoch 153/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8314\n","Epoch 154/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8299\n","Epoch 155/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3715 - accuracy: 0.8304\n","Epoch 156/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8281\n","Epoch 157/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3768 - accuracy: 0.8315\n","Epoch 158/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3683 - accuracy: 0.8327\n","Epoch 159/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3774 - accuracy: 0.8299\n","Epoch 160/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3719 - accuracy: 0.8339\n","Epoch 161/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3779 - accuracy: 0.8292\n","Epoch 162/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8307\n","Epoch 163/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3733 - accuracy: 0.8329\n","Epoch 164/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3692 - accuracy: 0.8332\n","Epoch 165/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3718 - accuracy: 0.8343\n","Epoch 166/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3730 - accuracy: 0.8307\n","Epoch 167/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3718 - accuracy: 0.8343\n","Epoch 168/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3695 - accuracy: 0.8352\n","Epoch 169/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3684 - accuracy: 0.8379\n","Epoch 170/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8331\n","Epoch 171/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8286\n","Epoch 172/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3711 - accuracy: 0.8374\n","Epoch 173/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3693 - accuracy: 0.8367\n","Epoch 174/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3693 - accuracy: 0.8344\n","Epoch 175/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3719 - accuracy: 0.8342\n","Epoch 176/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3694 - accuracy: 0.8347\n","Epoch 177/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3676 - accuracy: 0.8355\n","Epoch 178/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.8324\n","Epoch 179/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3665 - accuracy: 0.8356\n","Epoch 180/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3680 - accuracy: 0.8375\n","Epoch 181/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3640 - accuracy: 0.8381\n","Epoch 182/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3657 - accuracy: 0.8381\n","Epoch 183/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8413\n","Epoch 184/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3635 - accuracy: 0.8382\n","Epoch 185/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3629 - accuracy: 0.8375\n","Epoch 186/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3712 - accuracy: 0.8333\n","Epoch 187/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3665 - accuracy: 0.8357\n","Epoch 188/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3623 - accuracy: 0.8359\n","Epoch 189/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3688 - accuracy: 0.8356\n","Epoch 190/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8339\n","Epoch 191/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8369\n","Epoch 192/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3627 - accuracy: 0.8379\n","Epoch 193/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3601 - accuracy: 0.8399\n","Epoch 194/200\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3685 - accuracy: 0.8360\n","Epoch 195/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3685 - accuracy: 0.8335\n","Epoch 196/200\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3628 - accuracy: 0.8354\n","Epoch 197/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3586 - accuracy: 0.8417\n","Epoch 198/200\n","469/469 [==============================] - 2s 4ms/step - loss: 0.3595 - accuracy: 0.8395\n","Epoch 199/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3642 - accuracy: 0.8391\n","Epoch 200/200\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3585 - accuracy: 0.8413\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb9d0441310>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# deep_model2 with _MV_data\n","deep_model2 = keras.Sequential()\n","deep_model2.add(keras.layers.Dense(16, activation='leaky_relu', input_shape=(18,)))\n","deep_model2.add(keras.layers.Dense(8, activation='leaky_relu'))\n","deep_model2.add(keras.layers.Dense(4, activation='leaky_relu'))\n","deep_model2.add(keras.layers.Dense(2, activation='leaky_relu'))\n","deep_model2.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","# fit\n","deep_model2.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n","deep_model2.fit(MV_data_train, train_target, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m68IzgPHVWBv","executionInfo":{"status":"ok","timestamp":1661216070984,"user_tz":-540,"elapsed":88077,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"outputId":"c5dd75ea-5a75-4155-be57-4b7c55a774a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","469/469 [==============================] - 2s 2ms/step - loss: 0.5961 - accuracy: 0.6798\n","Epoch 2/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7031\n","Epoch 3/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5660 - accuracy: 0.7050\n","Epoch 4/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7074\n","Epoch 5/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7072\n","Epoch 6/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.7087\n","Epoch 7/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5623 - accuracy: 0.7105\n","Epoch 8/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5617 - accuracy: 0.7089\n","Epoch 9/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7118\n","Epoch 10/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5604 - accuracy: 0.7110\n","Epoch 11/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5601 - accuracy: 0.7110\n","Epoch 12/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5596 - accuracy: 0.7120\n","Epoch 13/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5593 - accuracy: 0.7129\n","Epoch 14/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7137\n","Epoch 15/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7125\n","Epoch 16/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5580 - accuracy: 0.7145\n","Epoch 17/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7141\n","Epoch 18/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5572 - accuracy: 0.7155\n","Epoch 19/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5569 - accuracy: 0.7142\n","Epoch 20/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5563 - accuracy: 0.7153\n","Epoch 21/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5560 - accuracy: 0.7155\n","Epoch 22/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5559 - accuracy: 0.7162\n","Epoch 23/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5558 - accuracy: 0.7165\n","Epoch 24/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7177\n","Epoch 25/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.7181\n","Epoch 26/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5551 - accuracy: 0.7183\n","Epoch 27/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5544 - accuracy: 0.7179\n","Epoch 28/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5539 - accuracy: 0.7177\n","Epoch 29/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5539 - accuracy: 0.7188\n","Epoch 30/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5536 - accuracy: 0.7183\n","Epoch 31/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5536 - accuracy: 0.7180\n","Epoch 32/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5530 - accuracy: 0.7194\n","Epoch 33/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.7181\n","Epoch 34/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5526 - accuracy: 0.7178\n","Epoch 35/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7185\n","Epoch 36/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5524 - accuracy: 0.7191\n","Epoch 37/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7218\n","Epoch 38/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5516 - accuracy: 0.7204\n","Epoch 39/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5513 - accuracy: 0.7205\n","Epoch 40/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5510 - accuracy: 0.7192\n","Epoch 41/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5503 - accuracy: 0.7210\n","Epoch 42/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7209\n","Epoch 43/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7238\n","Epoch 44/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7219\n","Epoch 45/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7225\n","Epoch 46/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7221\n","Epoch 47/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7219\n","Epoch 48/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7240\n","Epoch 49/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7237\n","Epoch 50/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5484 - accuracy: 0.7239\n","Epoch 51/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5484 - accuracy: 0.7251\n","Epoch 52/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5478 - accuracy: 0.7241\n","Epoch 53/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5474 - accuracy: 0.7243\n","Epoch 54/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5474 - accuracy: 0.7249\n","Epoch 55/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5470 - accuracy: 0.7254\n","Epoch 56/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5472 - accuracy: 0.7260\n","Epoch 57/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7253\n","Epoch 58/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7254\n","Epoch 59/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7270\n","Epoch 60/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7261\n","Epoch 61/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7275\n","Epoch 62/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7278\n","Epoch 63/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7271\n","Epoch 64/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7271\n","Epoch 65/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7258\n","Epoch 66/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7268\n","Epoch 67/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7269\n","Epoch 68/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7255\n","Epoch 69/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7291\n","Epoch 70/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7274\n","Epoch 71/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7278\n","Epoch 72/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7289\n","Epoch 73/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7274\n","Epoch 74/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7289\n","Epoch 75/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7277\n","Epoch 76/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7274\n","Epoch 77/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7279\n","Epoch 78/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7277\n","Epoch 79/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7265\n","Epoch 80/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7289\n","Epoch 81/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7282\n","Epoch 82/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7291\n","Epoch 83/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7287\n","Epoch 84/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7291\n","Epoch 85/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7287\n","Epoch 86/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7311\n","Epoch 87/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7285\n","Epoch 88/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7296\n","Epoch 89/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7284\n","Epoch 90/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7305\n","Epoch 91/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7283\n","Epoch 92/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7303\n","Epoch 93/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7309\n","Epoch 94/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7302\n","Epoch 95/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7297\n","Epoch 96/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7297\n","Epoch 97/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7301\n","Epoch 98/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7311\n","Epoch 99/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7299\n","Epoch 100/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7309\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb9d0362e50>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# deep_model3 with survey_data\n","deep_model3 = keras.Sequential()\n","deep_model3.add(keras.layers.Dense(16, activation='leaky_relu', input_shape=(25,)))\n","deep_model3.add(keras.layers.Dense(8, activation='leaky_relu'))\n","deep_model3.add(keras.layers.Dense(4, activation='leaky_relu'))\n","deep_model3.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","# fit\n","deep_model3.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n","deep_model3.fit(survey_data_train, train_target, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sA4tRVgVmkz","executionInfo":{"status":"ok","timestamp":1661216213811,"user_tz":-540,"elapsed":142841,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"outputId":"e4fb6b22-9613-4dc7-cd54-57632b9c126f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5827 - accuracy: 0.6865\n","Epoch 2/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7225\n","Epoch 3/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7229\n","Epoch 4/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7239\n","Epoch 5/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7259\n","Epoch 6/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7275\n","Epoch 7/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7291\n","Epoch 8/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7298\n","Epoch 9/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7298\n","Epoch 10/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7317\n","Epoch 11/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7338\n","Epoch 12/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7334\n","Epoch 13/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7339\n","Epoch 14/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7367\n","Epoch 15/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7354\n","Epoch 16/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7344\n","Epoch 17/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7367\n","Epoch 18/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7361\n","Epoch 19/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7387\n","Epoch 20/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7380\n","Epoch 21/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7360\n","Epoch 22/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7382\n","Epoch 23/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5259 - accuracy: 0.7387\n","Epoch 24/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7389\n","Epoch 25/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5249 - accuracy: 0.7404\n","Epoch 26/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5246 - accuracy: 0.7391\n","Epoch 27/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5237 - accuracy: 0.7399\n","Epoch 28/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5232 - accuracy: 0.7407\n","Epoch 29/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7407\n","Epoch 30/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7400\n","Epoch 31/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5223 - accuracy: 0.7403\n","Epoch 32/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.7411\n","Epoch 33/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7430\n","Epoch 34/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5214 - accuracy: 0.7430\n","Epoch 35/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 0.7429\n","Epoch 36/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5200 - accuracy: 0.7426\n","Epoch 37/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7411\n","Epoch 38/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7427\n","Epoch 39/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5186 - accuracy: 0.7441\n","Epoch 40/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5185 - accuracy: 0.7442\n","Epoch 41/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5179 - accuracy: 0.7438\n","Epoch 42/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.7452\n","Epoch 43/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7457\n","Epoch 44/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7451\n","Epoch 45/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.7454\n","Epoch 46/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7478\n","Epoch 47/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7476\n","Epoch 48/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7478\n","Epoch 49/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5148 - accuracy: 0.7474\n","Epoch 50/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5149 - accuracy: 0.7465\n","Epoch 51/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5145 - accuracy: 0.7471\n","Epoch 52/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.7472\n","Epoch 53/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5136 - accuracy: 0.7488\n","Epoch 54/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7485\n","Epoch 55/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7471\n","Epoch 56/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7483\n","Epoch 57/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5120 - accuracy: 0.7471\n","Epoch 58/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7478\n","Epoch 59/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7501\n","Epoch 60/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5114 - accuracy: 0.7474\n","Epoch 61/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5114 - accuracy: 0.7467\n","Epoch 62/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5110 - accuracy: 0.7510\n","Epoch 63/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5106 - accuracy: 0.7483\n","Epoch 64/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5104 - accuracy: 0.7484\n","Epoch 65/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5096 - accuracy: 0.7507\n","Epoch 66/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5095 - accuracy: 0.7491\n","Epoch 67/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7491\n","Epoch 68/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5090 - accuracy: 0.7493\n","Epoch 69/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5087 - accuracy: 0.7483\n","Epoch 70/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5088 - accuracy: 0.7511\n","Epoch 71/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5083 - accuracy: 0.7504\n","Epoch 72/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5087 - accuracy: 0.7486\n","Epoch 73/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7512\n","Epoch 74/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5077 - accuracy: 0.7507\n","Epoch 75/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7499\n","Epoch 76/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5077 - accuracy: 0.7503\n","Epoch 77/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.7494\n","Epoch 78/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5074 - accuracy: 0.7507\n","Epoch 79/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5073 - accuracy: 0.7498\n","Epoch 80/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5065 - accuracy: 0.7507\n","Epoch 81/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.7516\n","Epoch 82/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5065 - accuracy: 0.7531\n","Epoch 83/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.7519\n","Epoch 84/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7543\n","Epoch 85/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.7525\n","Epoch 86/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.7531\n","Epoch 87/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5051 - accuracy: 0.7535\n","Epoch 88/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.7533\n","Epoch 89/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7542\n","Epoch 90/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7529\n","Epoch 91/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5051 - accuracy: 0.7522\n","Epoch 92/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7555\n","Epoch 93/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7538\n","Epoch 94/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5041 - accuracy: 0.7558\n","Epoch 95/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7525\n","Epoch 96/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7529\n","Epoch 97/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.7535\n","Epoch 98/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.7557\n","Epoch 99/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7557\n","Epoch 100/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5034 - accuracy: 0.7533\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb9d01cc6d0>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# deep_model4 with pca_data\n","deep_model4 = keras.Sequential()\n","deep_model4.add(keras.layers.Dense(32, activation='leaky_relu', input_shape=(50,)))\n","deep_model4.add(keras.layers.Dropout(0.3))\n","deep_model4.add(keras.layers.Dense(16, activation='leaky_relu'))\n","deep_model4.add(keras.layers.Dense(8, activation='leaky_relu'))\n","deep_model4.add(keras.layers.Dense(4, activation='leaky_relu'))\n","deep_model4.add(keras.layers.Dense(2, activation='leaky_relu'))\n","deep_model4.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","# fit\n","deep_model4.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics='accuracy')\n","deep_model4.fit(pca_data_train, train_target, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oknsYX13VqRa","executionInfo":{"status":"ok","timestamp":1661216356539,"user_tz":-540,"elapsed":142737,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"outputId":"3de72ee8-25ff-4a6a-b4c1-83f6e53f70d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","469/469 [==============================] - 2s 2ms/step - loss: 0.6215 - accuracy: 0.6567\n","Epoch 2/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5749 - accuracy: 0.6968\n","Epoch 3/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5672 - accuracy: 0.6983\n","Epoch 4/100\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5628 - accuracy: 0.7019\n","Epoch 5/100\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5587 - accuracy: 0.7045\n","Epoch 6/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5592 - accuracy: 0.7041\n","Epoch 7/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.7076\n","Epoch 8/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5540 - accuracy: 0.7088\n","Epoch 9/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.7082\n","Epoch 10/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7105\n","Epoch 11/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.7123\n","Epoch 12/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5488 - accuracy: 0.7106\n","Epoch 13/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7151\n","Epoch 14/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5488 - accuracy: 0.7115\n","Epoch 15/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7143\n","Epoch 16/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7165\n","Epoch 17/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5450 - accuracy: 0.7153\n","Epoch 18/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7209\n","Epoch 19/100\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7171\n","Epoch 20/100\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7201\n","Epoch 21/100\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5407 - accuracy: 0.7209\n","Epoch 22/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7190\n","Epoch 23/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7219\n","Epoch 24/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7205\n","Epoch 25/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7205\n","Epoch 26/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7238\n","Epoch 27/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7219\n","Epoch 28/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7225\n","Epoch 29/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7252\n","Epoch 30/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7235\n","Epoch 31/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7240\n","Epoch 32/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7232\n","Epoch 33/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7255\n","Epoch 34/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7243\n","Epoch 35/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7287\n","Epoch 36/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7276\n","Epoch 37/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7277\n","Epoch 38/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7297\n","Epoch 39/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7314\n","Epoch 40/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7273\n","Epoch 41/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7279\n","Epoch 42/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7275\n","Epoch 43/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5289 - accuracy: 0.7284\n","Epoch 44/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7282\n","Epoch 45/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.7320\n","Epoch 46/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7310\n","Epoch 47/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5290 - accuracy: 0.7299\n","Epoch 48/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7333\n","Epoch 49/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.7321\n","Epoch 50/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7313\n","Epoch 51/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7303\n","Epoch 52/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5264 - accuracy: 0.7334\n","Epoch 53/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7346\n","Epoch 54/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7317\n","Epoch 55/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5254 - accuracy: 0.7349\n","Epoch 56/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7339\n","Epoch 57/100\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5247 - accuracy: 0.7343\n","Epoch 58/100\n","469/469 [==============================] - 2s 4ms/step - loss: 0.5230 - accuracy: 0.7346\n","Epoch 59/100\n","469/469 [==============================] - 1s 3ms/step - loss: 0.5255 - accuracy: 0.7337\n","Epoch 60/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5229 - accuracy: 0.7342\n","Epoch 61/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 0.7373\n","Epoch 62/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.7333\n","Epoch 63/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7405\n","Epoch 64/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 0.7368\n","Epoch 65/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7420\n","Epoch 66/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.7349\n","Epoch 67/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7387\n","Epoch 68/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7385\n","Epoch 69/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5211 - accuracy: 0.7360\n","Epoch 70/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7385\n","Epoch 71/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.7388\n","Epoch 72/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5211 - accuracy: 0.7387\n","Epoch 73/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7397\n","Epoch 74/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7415\n","Epoch 75/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7397\n","Epoch 76/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.7391\n","Epoch 77/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5210 - accuracy: 0.7353\n","Epoch 78/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7383\n","Epoch 79/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7384\n","Epoch 80/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5157 - accuracy: 0.7419\n","Epoch 81/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5168 - accuracy: 0.7401\n","Epoch 82/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7400\n","Epoch 83/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5168 - accuracy: 0.7403\n","Epoch 84/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7469\n","Epoch 85/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7457\n","Epoch 86/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5144 - accuracy: 0.7417\n","Epoch 87/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7395\n","Epoch 88/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7392\n","Epoch 89/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7413\n","Epoch 90/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7385\n","Epoch 91/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7405\n","Epoch 92/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5157 - accuracy: 0.7419\n","Epoch 93/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5157 - accuracy: 0.7437\n","Epoch 94/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7424\n","Epoch 95/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5160 - accuracy: 0.7397\n","Epoch 96/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7437\n","Epoch 97/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5145 - accuracy: 0.7431\n","Epoch 98/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7450\n","Epoch 99/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.7431\n","Epoch 100/100\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5137 - accuracy: 0.7465\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb9d00be8d0>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# ensemble\n","# 생성된 모델들을 이용해서 앙상블을 진행해본다.\n","def deep_result():\n","  final_pred = []\n","  preds = np.round(deep_model1.predict(full_data_test)) + np.round(deep_model2.predict(MV_data_test)) + np.round(deep_model3.predict(survey_data_test)) + np.round(deep_model4.predict(pca_data_test))\n","\n","  for pred in preds:\n","    if pred >= 2:\n","      final_pred.append(1)\n","    else:\n","      final_pred.append(0)\n","  \n","  return np.array(final_pred)"],"metadata":{"id":"DmoNk9UHWlLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["deep_result = deep_result()"],"metadata":{"id":"HMTg-WSdfQGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["deep_result[:30]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6FAnF8Wfxbv","executionInfo":{"status":"ok","timestamp":1661216361940,"user_tz":-540,"elapsed":26,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"outputId":"45f415fe-f30a-4931-e1d1-5c702c3333bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n","       1, 1, 0, 1, 1, 1, 1, 0])"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["###### 찍어낸 모델 테스트\n","전에 0.8을 넘긴 모델은 model1, model2, model3(ML Algorithm)만을 앙상블하여 생성한 것들이다.  \n","따라서, 그 코드를 그대로 재현해서 올리려고 한다."],"metadata":{"id":"9Vy36mkaOxWb"}},{"cell_type":"code","source":["# 모델이 예측한 값들을 찍어보는 코드\n","\n","# 일단 model4는 당시 사용을 안해서 일단은 주석처리를 해 두었다.\n","print(model1_pred[:10])\n","print(model2_pred[:10])\n","print(model3_pred[:10])\n","# print(model4_pred[:10]) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MK25WjybO0SO","executionInfo":{"status":"ok","timestamp":1661223881790,"user_tz":-540,"elapsed":537,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"outputId":"173ebcaa-54b4-4234-b3fe-5a6c02e6d33b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 1 1 0 0 1 1 0 0]\n","[0 1 1 1 1 0 1 0 1 0]\n","[0 1 1 1 1 0 1 1 0 0]\n"]}]},{"cell_type":"code","source":["# 딥러닝 예측 모델 deep_model1만 사용했다.\n","# 딥러닝 모델을 사용하고 싶다면 다른 것들을 추가해도 됩니다.\n","deep_model1_pred = np.round(deep_model1.predict(full_data_test))\n","deep_model1_pred = deep_model1_pred.reshape(-1)"],"metadata":{"id":"Xi_fWdItFN_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델의 예측값들을 hardvoting을 위해서 더한다.\n","# 당시재현을 위해서 model1, model2, model3만을 이용한다.\n","preds = model1_pred + model2_pred + model3_pred #+ model4_pred + deep_model1_pred"],"metadata":{"id":"_jY3lkzq-V7v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트로 값을 찍어본다.\n","preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1egzygxicLlx","executionInfo":{"status":"ok","timestamp":1661223912742,"user_tz":-540,"elapsed":423,"user":{"displayName":"SEONG SU MOON","userId":"16958296455928153314"}},"outputId":"1a0cbdfc-8842-4a18-a504-09bc17377e72"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 3, 3, ..., 3, 0, 2])"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["# 최종 모델의 결정을 위한 앙상블 학습\n","# hard voting ensemble\n","predict_final = []\n","for pred in preds:\n","  if pred >= 1.5:\n","    predict_final.append(1)\n","  else:\n","    predict_final.append(0)\n","\n","result = np.array(predict_final)  # 최종 생성 결과"],"metadata":{"id":"ZziwqIPMaBWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 제출 파일 생성\n","submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DACON/sample_submission.csv')\n","submission[\"nerdiness\"] = result\n","\n","# 생성된 CSV 파일 저장하는 코드\n","# 코랩에서 작업시 작업 디렉터리에 생성되며 이를 로컬로 다운 받아 제출을 해 주어야 한다.\n","submission.to_csv(\"submission14.csv\", index = False)"],"metadata":{"id":"eEuhAIBtbEFa"},"execution_count":null,"outputs":[]}]}